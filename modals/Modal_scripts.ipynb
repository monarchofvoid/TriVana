{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RDsRPfTmQdX",
        "outputId": "11193bb4-1019-40c8-86e7-d2b008cebb77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“ Column Names:\n",
            "['kepid', 'kepoi_name', 'kepler_name', 'koi_disposition', 'koi_pdisposition', 'koi_score', 'koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co', 'koi_fpflag_ec', 'koi_period', 'koi_period_err1', 'koi_period_err2', 'koi_time0bk', 'koi_time0bk_err1', 'koi_time0bk_err2', 'koi_impact', 'koi_impact_err1', 'koi_impact_err2', 'koi_duration', 'koi_duration_err1', 'koi_duration_err2', 'koi_depth', 'koi_depth_err1', 'koi_depth_err2', 'koi_prad', 'koi_prad_err1', 'koi_prad_err2', 'koi_teq', 'koi_teq_err1', 'koi_teq_err2', 'koi_insol', 'koi_insol_err1', 'koi_insol_err2', 'koi_model_snr', 'koi_tce_plnt_num', 'koi_tce_delivname', 'koi_steff', 'koi_steff_err1', 'koi_steff_err2', 'koi_slogg', 'koi_slogg_err1', 'koi_slogg_err2', 'koi_srad', 'koi_srad_err1', 'koi_srad_err2', 'ra', 'dec', 'koi_kepmag']\n",
            "\n",
            "Total Columns: 49\n",
            "\n",
            "ğŸ”¹ First 10 values for each column:\n",
            "\n",
            "--- kepid ---\n",
            "[3541800, 3115833, 4673628, 4055092, 3440118, 3441340, 4752451, 3554819, 5097470, 3757588]\n",
            "\n",
            "--- kepoi_name ---\n",
            "['K00491.01', 'K00797.01', 'K04056.01', 'K06379.01', 'K03876.01', 'K06335.01', 'K00109.01', 'K04993.01', 'K02767.01', 'K06356.01']\n",
            "\n",
            "--- kepler_name ---\n",
            "[nan, nan, 'Kepler-1935 b', nan, 'Kepler-1928 b', nan, nan, nan, nan, nan]\n",
            "\n",
            "--- koi_disposition ---\n",
            "['FALSE POSITIVE', 'CANDIDATE', 'CONFIRMED', 'FALSE POSITIVE', 'CONFIRMED', 'FALSE POSITIVE', 'FALSE POSITIVE', 'FALSE POSITIVE', 'FALSE POSITIVE', 'FALSE POSITIVE']\n",
            "\n",
            "--- koi_pdisposition ---\n",
            "['FALSE POSITIVE', 'CANDIDATE', 'CANDIDATE', 'FALSE POSITIVE', 'CANDIDATE', 'FALSE POSITIVE', 'FALSE POSITIVE', 'FALSE POSITIVE', 'FALSE POSITIVE', 'FALSE POSITIVE']\n",
            "\n",
            "--- koi_score ---\n",
            "[0.0, 1.0, 0.838, 0.0, 1.0, 0.0, 0.0, nan, 0.0, 0.0]\n",
            "\n",
            "--- koi_fpflag_nt ---\n",
            "[0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "--- koi_fpflag_ss ---\n",
            "[0, 0, 0, 1, 0, 1, 1, 0, 1, 1]\n",
            "\n",
            "--- koi_fpflag_co ---\n",
            "[1, 0, 0, 0, 0, 1, 1, 0, 1, 0]\n",
            "\n",
            "--- koi_fpflag_ec ---\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "--- koi_period ---\n",
            "[4.66229074, 10.181584004, 3.951383138, 76.45315813, 19.57783279, 0.806277023, 6.41496453, 43.22793081, 1.28805834, 24.09002065]\n",
            "\n",
            "--- koi_period_err1 ---\n",
            "[1.657e-05, 6.188e-06, 6.251e-06, 7.982e-05, 3.696e-05, 4.947e-06, 1.252e-05, nan, 7.457e-06, 2.959e-05]\n",
            "\n",
            "--- koi_period_err2 ---\n",
            "[-1.657e-05, -6.188e-06, -6.251e-06, -7.982e-05, -3.696e-05, -4.947e-06, -1.252e-05, nan, -7.457e-06, -2.959e-05]\n",
            "\n",
            "--- koi_time0bk ---\n",
            "[169.65558, 177.141891, 132.06462, 133.986308, 131.71421, 131.78567, 132.86482, 144.4486525, 131.9914, 154.285323]\n",
            "\n",
            "--- koi_time0bk_err1 ---\n",
            "[0.00291, 0.000483, 0.00118, 0.000842, 0.00153, 0.00672, 0.00157, nan, 0.00478, 0.000985]\n",
            "\n",
            "--- koi_time0bk_err2 ---\n",
            "[-0.00291, -0.000483, -0.00118, -0.000842, -0.00153, -0.00672, -0.00157, nan, -0.00478, -0.000985]\n",
            "\n",
            "--- koi_impact ---\n",
            "[1.197, 0.92, 1.217, 1.26, 0.694, 0.697, 1.187, nan, 0.214, 0.946]\n",
            "\n",
            "--- koi_impact_err1 ---\n",
            "[15.17, 0.007, 6.718, 0.576, 0.007, 0.26, 6.629, nan, 0.26, 0.018]\n",
            "\n",
            "--- koi_impact_err2 ---\n",
            "[-0.332, -0.005, -0.13, -0.186, -0.509, -0.451, -0.013, nan, -0.214, -0.012]\n",
            "\n",
            "--- koi_duration ---\n",
            "[3.73, 3.5089, 1.0582, 5.1822, 1.9857, 7.275, 3.9015, 1.39, 3.419, 11.0494]\n",
            "\n",
            "--- koi_duration_err1 ---\n",
            "[0.172, 0.0331, 0.0787, 0.0432, 0.048, 0.312, 0.0902, nan, 0.171, 0.0821]\n",
            "\n",
            "--- koi_duration_err2 ---\n",
            "[-0.172, -0.0331, -0.0787, -0.0432, -0.048, -0.312, -0.0902, nan, -0.171, -0.0821]\n",
            "\n",
            "--- koi_depth ---\n",
            "[345.4, 5741.1, 405.7, 9662.2, 432.6, 70.8, 201.2, nan, 92.6, 6782.2]\n",
            "\n",
            "--- koi_depth_err1 ---\n",
            "[14.1, 53.2, 20.6, 75.8, 13.5, 3.8, 4.4, nan, 3.8, 40.2]\n",
            "\n",
            "--- koi_depth_err2 ---\n",
            "[-14.1, -53.2, -20.6, -75.8, -13.5, -3.8, -4.4, nan, -3.8, -40.2]\n",
            "\n",
            "--- koi_prad ---\n",
            "[24.12, 7.73, 23.51, 22.89, 1.96, 0.89, 25.79, nan, 1.08, 9.39]\n",
            "\n",
            "--- koi_prad_err1 ---\n",
            "[6.89, 2.17, 5.67, 1.1, 0.27, 0.29, 5.27, nan, 0.17, 1.49]\n",
            "\n",
            "--- koi_prad_err2 ---\n",
            "[-2.47, -0.72, -3.06, -1.49, -0.09, -0.09, -5.28, nan, -0.14, -1.23]\n",
            "\n",
            "--- koi_teq ---\n",
            "[1166.0, 812.0, 1083.0, 291.0, 621.0, 2046.0, 1153.0, nan, 1736.0, 551.0]\n",
            "\n",
            "--- koi_teq_err1 ---\n",
            "[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
            "\n",
            "--- koi_teq_err2 ---\n",
            "[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
            "\n",
            "--- koi_insol ---\n",
            "[437.35, 102.91, 324.78, 1.7, 35.14, 4119.09, 417.97, nan, 2142.23, 21.85]\n",
            "\n",
            "--- koi_insol_err1 ---\n",
            "[369.54, 86.75, 238.09, 0.4, 13.8, 3927.86, 257.72, nan, 875.49, 11.59]\n",
            "\n",
            "--- koi_insol_err2 ---\n",
            "[-131.67, -28.91, -104.3, -0.4, -5.49, -1221.11, -184.3, nan, -596.68, -7.22]\n",
            "\n",
            "--- koi_model_snr ---\n",
            "[29.8, 183.6, 23.9, 151.8, 37.2, 37.9, 53.1, nan, 28.1, 252.3]\n",
            "\n",
            "--- koi_tce_plnt_num ---\n",
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "\n",
            "--- koi_tce_delivname ---\n",
            "['q1_q17_dr25_tce', 'q1_q17_dr25_tce', 'q1_q17_dr25_tce', 'q1_q17_dr25_tce', 'q1_q17_dr25_tce', 'q1_q17_dr25_tce', 'q1_q17_dr25_tce', 'q1_q16_tce', 'q1_q17_dr25_tce', 'q1_q17_dr25_tce']\n",
            "\n",
            "--- koi_steff ---\n",
            "[6191.0, 5988.0, 5570.0, 4831.0, 5620.0, 6122.0, 6170.0, nan, 5631.0, 5354.0]\n",
            "\n",
            "--- koi_steff_err1 ---\n",
            "[172.0, 179.0, 166.0, 144.0, 100.0, 165.0, 169.0, nan, 76.0, 177.0]\n",
            "\n",
            "--- koi_steff_err2 ---\n",
            "[-216.0, -197.0, -149.0, -158.0, -111.0, -184.0, -188.0, nan, -76.0, -160.0]\n",
            "\n",
            "--- koi_slogg ---\n",
            "[4.454, 4.541, 4.458, 4.713, 4.533, 4.471, 4.259, nan, 4.33, 4.495]\n",
            "\n",
            "--- koi_slogg_err1 ---\n",
            "[0.05, 0.048, 0.104, 0.049, 0.023, 0.054, 0.186, nan, 0.115, 0.105]\n",
            "\n",
            "--- koi_slogg_err2 ---\n",
            "[-0.2, -0.192, -0.169, -0.025, -0.113, -0.229, -0.124, nan, -0.115, -0.116]\n",
            "\n",
            "--- koi_srad ---\n",
            "[1.025, 0.836, 0.899, 0.54, 0.884, 0.996, 1.183, nan, 1.132, 0.804]\n",
            "\n",
            "--- koi_srad_err1 ---\n",
            "[0.293, 0.234, 0.217, 0.026, 0.123, 0.324, 0.242, nan, 0.176, 0.128]\n",
            "\n",
            "--- koi_srad_err2 ---\n",
            "[-0.105, -0.078, -0.117, -0.035, -0.039, -0.108, -0.242, nan, -0.144, -0.105]\n",
            "\n",
            "--- ra ---\n",
            "[290.62134, 291.28195, 296.40375, 290.98013, 290.44067, 290.81723, 293.45428, 293.99844, 291.25308, 294.1434]\n",
            "\n",
            "--- dec ---\n",
            "[38.695499, 38.241669, 39.722649, 39.186489, 38.52356, 38.53912, 39.803928, 38.617439, 40.216671, 38.893162]\n",
            "\n",
            "--- koi_kepmag ---\n",
            "[14.367, 15.657, 14.368, 15.312, 12.624, 13.614, 12.385, 12.654, 14.487, 14.94]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Load cumulative label file\n",
        "labels = pd.read_csv(\"/content/all_features.csv\")\n",
        "\n",
        "# Example labels.csv columns: kepid, disposition\n",
        "# disposition could be \"CONFIRMED\", \"FALSE POSITIVE\", etc.\n",
        "print(\"ğŸ“ Column Names:\")\n",
        "print(labels.columns.tolist())\n",
        "print(\"\\nTotal Columns:\", len(labels.columns))\n",
        "\n",
        "# Display first 10 values for each column\n",
        "print(\"\\nğŸ”¹ First 10 values for each column:\\n\")\n",
        "for col in labels.columns:\n",
        "    print(f\"--- {col} ---\")\n",
        "    print(labels[col].head(10).to_list())  # convert to list for cleaner display\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the original metadata file\n",
        "file_path = \"/content/all_features.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# âœ… Columns we want to keep\n",
        "columns_to_keep = [\n",
        "    'kepid',              # Unique identifier\n",
        "    'koi_disposition',    # Planet label (CONFIRMED / FALSE POSITIVE)\n",
        "    'koi_period',         # Transit period\n",
        "    'koi_depth',          # Transit depth\n",
        "    'koi_prad',           # Planet radius (if available)\n",
        "    'koi_teq',            # Equilibrium temperature (optional)\n",
        "    'koi_steff',          # Stellar effective temperature\n",
        "    'koi_srad',           # Stellar radius\n",
        "    'koi_model_snr'       # Signal-to-noise ratio\n",
        "]\n",
        "\n",
        "# Filter the DataFrame to keep only these columns\n",
        "clean_df = df[columns_to_keep].copy()\n",
        "\n",
        "# Optional: drop rows with missing critical values (like kepid or disposition)\n",
        "clean_df.dropna(subset=['kepid', 'koi_disposition'], inplace=True)\n",
        "\n",
        "# Save to a new CSV file\n",
        "output_path = \"/content/clean_labels.csv\"\n",
        "clean_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"âœ… Cleaned file saved at: {output_path}\")\n",
        "print(\"ğŸ“ Columns in clean file:\", clean_df.columns.tolist())\n",
        "print(\"\\nğŸ“Š Preview:\")\n",
        "print(clean_df.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzzcP2-rramQ",
        "outputId": "a6b6c669-83f3-4b93-b2fa-ba8f689f10f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Cleaned file saved at: /content/clean_labels.csv\n",
            "ğŸ“ Columns in clean file: ['kepid', 'koi_disposition', 'koi_period', 'koi_depth', 'koi_prad', 'koi_teq', 'koi_steff', 'koi_srad', 'koi_model_snr']\n",
            "\n",
            "ğŸ“Š Preview:\n",
            "     kepid koi_disposition  koi_period  koi_depth  koi_prad  koi_teq  \\\n",
            "0  3541800  FALSE POSITIVE    4.662291      345.4     24.12   1166.0   \n",
            "1  3115833       CANDIDATE   10.181584     5741.1      7.73    812.0   \n",
            "2  4673628       CONFIRMED    3.951383      405.7     23.51   1083.0   \n",
            "3  4055092  FALSE POSITIVE   76.453158     9662.2     22.89    291.0   \n",
            "4  3440118       CONFIRMED   19.577833      432.6      1.96    621.0   \n",
            "5  3441340  FALSE POSITIVE    0.806277       70.8      0.89   2046.0   \n",
            "6  4752451  FALSE POSITIVE    6.414965      201.2     25.79   1153.0   \n",
            "7  3554819  FALSE POSITIVE   43.227931        NaN       NaN      NaN   \n",
            "8  5097470  FALSE POSITIVE    1.288058       92.6      1.08   1736.0   \n",
            "9  3757588  FALSE POSITIVE   24.090021     6782.2      9.39    551.0   \n",
            "\n",
            "   koi_steff  koi_srad  koi_model_snr  \n",
            "0     6191.0     1.025           29.8  \n",
            "1     5988.0     0.836          183.6  \n",
            "2     5570.0     0.899           23.9  \n",
            "3     4831.0     0.540          151.8  \n",
            "4     5620.0     0.884           37.2  \n",
            "5     6122.0     0.996           37.9  \n",
            "6     6170.0     1.183           53.1  \n",
            "7        NaN       NaN            NaN  \n",
            "8     5631.0     1.132           28.1  \n",
            "9     5354.0     0.804          252.3  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Constants\n",
        "G = 6.67430e-11  # gravitational constant (m^3 kg^-1 s^-2)\n",
        "M_sun = 1.98847e30  # solar mass in kg\n",
        "R_sun = 6.957e8     # solar radius in m\n",
        "AU = 1.495978707e11 # 1 AU in m\n",
        "SECONDS_PER_DAY = 86400\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"/content/clean_labels.csv\")\n",
        "\n",
        "# Helper: estimate stellar mass using logg and radius (if available)\n",
        "def estimate_stellar_mass(logg, r_star_rsun):\n",
        "    \"\"\"Estimate stellar mass using surface gravity and radius.\"\"\"\n",
        "    if np.isnan(logg) or np.isnan(r_star_rsun):\n",
        "        return 1.0 * M_sun  # assume solar mass\n",
        "    g_star = 10**logg      # in cm/sÂ²\n",
        "    g_star_mks = g_star / 100  # convert to m/sÂ²\n",
        "    r_star_m = r_star_rsun * R_sun\n",
        "    m_star = g_star_mks * r_star_m**2 / G\n",
        "    return m_star\n",
        "\n",
        "# Orbital distance (AU)\n",
        "def compute_orbital_distance(period_days, m_star):\n",
        "    if np.isnan(period_days):\n",
        "        return np.nan\n",
        "    P_sec = period_days * SECONDS_PER_DAY\n",
        "    a_m = ((G * m_star * P_sec**2) / (4 * np.pi**2))**(1/3)\n",
        "    return a_m / AU\n",
        "\n",
        "# Planet radius (Earth radii)\n",
        "def compute_planet_radius(r_planet_col, depth_ppm, r_star_rsun):\n",
        "    if not np.isnan(r_planet_col):\n",
        "        return r_planet_col  # koi_prad already in Earth radii\n",
        "    if np.isnan(depth_ppm) or np.isnan(r_star_rsun):\n",
        "        return np.nan\n",
        "    # Convert depth from ppm to fractional\n",
        "    depth_frac = depth_ppm / 1e6\n",
        "    r_star_m = r_star_rsun * R_sun\n",
        "    r_planet_m = r_star_m * np.sqrt(depth_frac)\n",
        "    r_earth_m = 6.371e6\n",
        "    return r_planet_m / r_earth_m\n",
        "\n",
        "# Planet mass (empirical)\n",
        "def compute_planet_mass(r_p_earth):\n",
        "    if np.isnan(r_p_earth):\n",
        "        return np.nan\n",
        "    # Simple Weiss+Marcy power-law\n",
        "    return r_p_earth ** 3.7  # in Earth masses\n",
        "\n",
        "# Planet density (g/cmÂ³)\n",
        "def compute_density(m_p_earth, r_p_earth):\n",
        "    if np.isnan(m_p_earth) or np.isnan(r_p_earth):\n",
        "        return np.nan\n",
        "    M_earth = 5.972e24  # kg\n",
        "    R_earth = 6.371e6   # m\n",
        "    m_kg = m_p_earth * M_earth\n",
        "    r_m = r_p_earth * R_earth\n",
        "    volume = 4/3 * np.pi * r_m**3\n",
        "    rho = m_kg / volume  # kg/mÂ³\n",
        "    return rho / 1000  # g/cmÂ³\n",
        "\n",
        "# Equilibrium temperature (K)\n",
        "def compute_teq(teq, t_star, r_star_rsun, a_au):\n",
        "    if not np.isnan(teq):\n",
        "        return teq\n",
        "    if np.isnan(t_star) or np.isnan(r_star_rsun) or np.isnan(a_au):\n",
        "        return np.nan\n",
        "    A = 0.3  # assumed albedo\n",
        "    r_star_m = r_star_rsun * R_sun\n",
        "    a_m = a_au * AU\n",
        "    return t_star * np.sqrt(r_star_m / (2 * a_m)) * (1 - A)**0.25\n",
        "\n",
        "# Apply computations\n",
        "pl_orbsmax_list, pl_rade_list, pl_masse_list, pl_dens_list, pl_eqt_list = [], [], [], [], []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    m_star = estimate_stellar_mass(row.get('koi_slogg', np.nan), row.get('koi_srad', np.nan))\n",
        "    a_au = compute_orbital_distance(row['koi_period'], m_star)\n",
        "    pl_orbsmax_list.append(a_au)\n",
        "\n",
        "    r_p = compute_planet_radius(row.get('koi_prad', np.nan), row.get('koi_depth', np.nan), row.get('koi_srad', np.nan))\n",
        "    pl_rade_list.append(r_p)\n",
        "\n",
        "    m_p = compute_planet_mass(r_p)\n",
        "    pl_masse_list.append(m_p)\n",
        "\n",
        "    rho_p = compute_density(m_p, r_p)\n",
        "    pl_dens_list.append(rho_p)\n",
        "\n",
        "    teq_p = compute_teq(row.get('koi_teq', np.nan), row.get('koi_steff', np.nan), row.get('koi_srad', np.nan), a_au)\n",
        "    pl_eqt_list.append(teq_p)\n",
        "\n",
        "# Add to DataFrame\n",
        "df['pl_orbsmax'] = pl_orbsmax_list\n",
        "df['pl_rade'] = pl_rade_list\n",
        "df['pl_masse'] = pl_masse_list\n",
        "df['pl_dens'] = pl_dens_list\n",
        "df['pl_eqt'] = pl_eqt_list\n",
        "\n",
        "# Save\n",
        "df.to_csv(\"/content/clean_labels_with_derived.csv\", index=False)\n",
        "print(\"âœ… Derived physical features added and saved to /content/clean_labels_with_derived.csv\")\n",
        "print(df[['kepid','pl_orbsmax','pl_rade','pl_masse','pl_dens','pl_eqt']].head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDMeMQln1WK_",
        "outputId": "9f1dc848-323a-4950-c77c-201f171ac085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Derived physical features added and saved to /content/clean_labels_with_derived.csv\n",
            "     kepid  pl_orbsmax  pl_rade       pl_masse    pl_dens  pl_eqt\n",
            "0  3541800    0.054618    24.12  130255.485759  51.176725  1166.0\n",
            "1  3115833    0.091935     7.73    1933.143651  23.074591   812.0\n",
            "2  4673628    0.048915    23.51  118477.185245  50.267260  1083.0\n",
            "3  4055092    0.352535    22.89  107322.166934  49.335602   291.0\n",
            "4  3440118    0.142161     1.96      12.060004   8.830547   621.0\n",
            "5  3441340    0.016954     0.89       0.649745   5.081377  2046.0\n",
            "6  4752451    0.067567    25.79  166866.810888  53.632040  1153.0\n",
            "7  3554819    0.241054      NaN            NaN        NaN     NaN\n",
            "8  5097470    0.023168     1.08       1.329437   5.818419  1736.0\n",
            "9  3757588    0.163241     9.39    3970.659913  26.440782   551.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Paths\n",
        "labels_csv = \"/content/clean_labels_with_derived.csv\"\n",
        "lightcurve_folder = \"/content/drive/MyDrive/Data\"\n",
        "\n",
        "# Load CSV\n",
        "df = pd.read_csv(labels_csv)\n",
        "\n",
        "# 1ï¸âƒ£ Convert koi_disposition to binary\n",
        "df['target'] = df['koi_disposition'].apply(lambda x: 1 if x in ['CONFIRMED', 'CANDIDATE'] else 0)\n",
        "\n",
        "# 2ï¸âƒ£ Map lightcurve files for each kepid\n",
        "def get_lightcurve_file(kepid):\n",
        "    filename = f\"kepler_{kepid}_lightcurve.csv\"\n",
        "    file_path = os.path.join(lightcurve_folder, filename)\n",
        "    if os.path.exists(file_path):\n",
        "        return file_path\n",
        "    else:\n",
        "        return None  # or \"\" if you prefer\n",
        "\n",
        "df['lightcurve_file'] = df['kepid'].apply(get_lightcurve_file)\n",
        "\n",
        "# Optional: drop rows with no corresponding lightcurve\n",
        "df = df.dropna(subset=['lightcurve_file']).reset_index(drop=True)\n",
        "\n",
        "# Save updated CSV\n",
        "output_csv = \"/content/clean_labels_with_derived_binary.csv\"\n",
        "df.to_csv(output_csv, index=False)\n",
        "\n",
        "print(f\"âœ… Updated CSV saved at: {output_csv}\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peqs6QH5_Sc3",
        "outputId": "66d81c0c-13b4-46c5-edb2-fe9f23b0d292"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Updated CSV saved at: /content/clean_labels_with_derived_binary.csv\n",
            "     kepid koi_disposition  koi_period  koi_depth  koi_prad  koi_teq  \\\n",
            "0  3541800  FALSE POSITIVE    4.662291      345.4     24.12   1166.0   \n",
            "1  3115833       CANDIDATE   10.181584     5741.1      7.73    812.0   \n",
            "2  4673628       CONFIRMED    3.951383      405.7     23.51   1083.0   \n",
            "3  4055092  FALSE POSITIVE   76.453158     9662.2     22.89    291.0   \n",
            "4  3440118       CONFIRMED   19.577833      432.6      1.96    621.0   \n",
            "\n",
            "   koi_steff  koi_srad  koi_model_snr  pl_orbsmax  pl_rade       pl_masse  \\\n",
            "0     6191.0     1.025           29.8    0.054618    24.12  130255.485759   \n",
            "1     5988.0     0.836          183.6    0.091935     7.73    1933.143651   \n",
            "2     5570.0     0.899           23.9    0.048915    23.51  118477.185245   \n",
            "3     4831.0     0.540          151.8    0.352535    22.89  107322.166934   \n",
            "4     5620.0     0.884           37.2    0.142161     1.96      12.060004   \n",
            "\n",
            "     pl_dens  pl_eqt  target  \\\n",
            "0  51.176725  1166.0       0   \n",
            "1  23.074591   812.0       1   \n",
            "2  50.267260  1083.0       1   \n",
            "3  49.335602   291.0       0   \n",
            "4   8.830547   621.0       1   \n",
            "\n",
            "                                     lightcurve_file  \n",
            "0  /content/drive/MyDrive/Data/kepler_3541800_lig...  \n",
            "1  /content/drive/MyDrive/Data/kepler_3115833_lig...  \n",
            "2  /content/drive/MyDrive/Data/kepler_4673628_lig...  \n",
            "3  /content/drive/MyDrive/Data/kepler_4055092_lig...  \n",
            "4  /content/drive/MyDrive/Data/kepler_3440118_lig...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3ï¸âƒ£ Drop koi_disposition and kepid\n",
        "df = df.drop(columns=['koi_disposition', 'kepid'])\n",
        "\n",
        "# Save updated CSV\n",
        "output_csv = \"/content/clean_labels_prepared.csv\"\n",
        "df.to_csv(output_csv, index=False)\n",
        "\n",
        "print(f\"âœ… Prepared CSV saved at: {output_csv}\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyd-zu6G_nl1",
        "outputId": "79bbd789-6363-4f88-fbf7-364f4764b53e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Prepared CSV saved at: /content/clean_labels_prepared.csv\n",
            "   koi_period  koi_depth  koi_prad  koi_teq  koi_steff  koi_srad  \\\n",
            "0    4.662291      345.4     24.12   1166.0     6191.0     1.025   \n",
            "1   10.181584     5741.1      7.73    812.0     5988.0     0.836   \n",
            "2    3.951383      405.7     23.51   1083.0     5570.0     0.899   \n",
            "3   76.453158     9662.2     22.89    291.0     4831.0     0.540   \n",
            "4   19.577833      432.6      1.96    621.0     5620.0     0.884   \n",
            "\n",
            "   koi_model_snr  pl_orbsmax  pl_rade       pl_masse    pl_dens  pl_eqt  \\\n",
            "0           29.8    0.054618    24.12  130255.485759  51.176725  1166.0   \n",
            "1          183.6    0.091935     7.73    1933.143651  23.074591   812.0   \n",
            "2           23.9    0.048915    23.51  118477.185245  50.267260  1083.0   \n",
            "3          151.8    0.352535    22.89  107322.166934  49.335602   291.0   \n",
            "4           37.2    0.142161     1.96      12.060004   8.830547   621.0   \n",
            "\n",
            "   target                                    lightcurve_file  \n",
            "0       0  /content/drive/MyDrive/Data/kepler_3541800_lig...  \n",
            "1       1  /content/drive/MyDrive/Data/kepler_3115833_lig...  \n",
            "2       1  /content/drive/MyDrive/Data/kepler_4673628_lig...  \n",
            "3       0  /content/drive/MyDrive/Data/kepler_4055092_lig...  \n",
            "4       1  /content/drive/MyDrive/Data/kepler_3440118_lig...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/clean_labels_prepared.csv')\n",
        "print(df.head())\n",
        "print(df.isna().sum())  # Check missing data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldhzgbawDpQ2",
        "outputId": "924e3d66-ea5d-42b2-cefa-1028d89b7d5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   koi_period  koi_depth  koi_prad  koi_teq  koi_steff  koi_srad  \\\n",
            "0    4.662291      345.4     24.12   1166.0     6191.0     1.025   \n",
            "1   10.181584     5741.1      7.73    812.0     5988.0     0.836   \n",
            "2    3.951383      405.7     23.51   1083.0     5570.0     0.899   \n",
            "3   76.453158     9662.2     22.89    291.0     4831.0     0.540   \n",
            "4   19.577833      432.6      1.96    621.0     5620.0     0.884   \n",
            "\n",
            "   koi_model_snr  pl_orbsmax  pl_rade       pl_masse    pl_dens  pl_eqt  \\\n",
            "0           29.8    0.054618    24.12  130255.485759  51.176725  1166.0   \n",
            "1          183.6    0.091935     7.73    1933.143651  23.074591   812.0   \n",
            "2           23.9    0.048915    23.51  118477.185245  50.267260  1083.0   \n",
            "3          151.8    0.352535    22.89  107322.166934  49.335602   291.0   \n",
            "4           37.2    0.142161     1.96      12.060004   8.830547   621.0   \n",
            "\n",
            "   target                                    lightcurve_file  \n",
            "0       0  /content/drive/MyDrive/Data/kepler_3541800_lig...  \n",
            "1       1  /content/drive/MyDrive/Data/kepler_3115833_lig...  \n",
            "2       1  /content/drive/MyDrive/Data/kepler_4673628_lig...  \n",
            "3       0  /content/drive/MyDrive/Data/kepler_4055092_lig...  \n",
            "4       1  /content/drive/MyDrive/Data/kepler_3440118_lig...  \n",
            "koi_period           0\n",
            "koi_depth          205\n",
            "koi_prad           205\n",
            "koi_teq            205\n",
            "koi_steff          205\n",
            "koi_srad           205\n",
            "koi_model_snr      205\n",
            "pl_orbsmax           0\n",
            "pl_rade            205\n",
            "pl_masse           205\n",
            "pl_dens            205\n",
            "pl_eqt             205\n",
            "target               0\n",
            "lightcurve_file      0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your prepared full dataset\n",
        "df = pd.read_csv('/content/clean_labels_prepared.csv')\n",
        "\n",
        "# Keep only necessary columns for existence classification\n",
        "df_exist = df[['target', 'lightcurve_file']]\n",
        "\n",
        "# Save the new CSV\n",
        "exist_csv_path = '/content/labels_existence.csv'\n",
        "df_exist.to_csv(exist_csv_path, index=False)\n",
        "\n",
        "print(f\"Existence label file saved at: {exist_csv_path}\")\n",
        "print(df_exist.head())\n",
        "print(\"Total samples:\", len(df_exist))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8trCS4LREyLx",
        "outputId": "06cfd996-ea8c-41ed-fa60-8005cb762176"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Existence label file saved at: /content/labels_existence.csv\n",
            "   target                                    lightcurve_file\n",
            "0       0  /content/drive/MyDrive/Data/kepler_3541800_lig...\n",
            "1       1  /content/drive/MyDrive/Data/kepler_3115833_lig...\n",
            "2       1  /content/drive/MyDrive/Data/kepler_4673628_lig...\n",
            "3       0  /content/drive/MyDrive/Data/kepler_4055092_lig...\n",
            "4       1  /content/drive/MyDrive/Data/kepler_3440118_lig...\n",
            "Total samples: 5190\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load full prepared dataset\n",
        "df = pd.read_csv('/content/clean_labels_prepared.csv')\n",
        "\n",
        "# Columns required for regression\n",
        "feature_cols = [\n",
        "    'koi_period','koi_depth','koi_prad','koi_teq','koi_steff',\n",
        "    'koi_srad','koi_model_snr','pl_orbsmax','pl_rade','pl_masse','pl_dens','pl_eqt'\n",
        "]\n",
        "\n",
        "# Keep only rows with no missing values in features\n",
        "df_features = df.dropna(subset=feature_cols)\n",
        "\n",
        "# Keep lightcurve file path as input\n",
        "df_features = df_features[feature_cols + ['lightcurve_file']]\n",
        "\n",
        "# Save CSV\n",
        "feature_csv_path = '/content/labels_features.csv'\n",
        "df_features.to_csv(feature_csv_path, index=False)\n",
        "\n",
        "print(f\"Feature regression label file saved at: {feature_csv_path}\")\n",
        "print(\"Total samples for feature regression:\", len(df_features))\n",
        "print(df_features.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdCGR3MYFycb",
        "outputId": "38675f39-496b-47ea-d9b5-bf247081cff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature regression label file saved at: /content/labels_features.csv\n",
            "Total samples for feature regression: 4985\n",
            "   koi_period  koi_depth  koi_prad  koi_teq  koi_steff  koi_srad  \\\n",
            "0    4.662291      345.4     24.12   1166.0     6191.0     1.025   \n",
            "1   10.181584     5741.1      7.73    812.0     5988.0     0.836   \n",
            "2    3.951383      405.7     23.51   1083.0     5570.0     0.899   \n",
            "3   76.453158     9662.2     22.89    291.0     4831.0     0.540   \n",
            "4   19.577833      432.6      1.96    621.0     5620.0     0.884   \n",
            "\n",
            "   koi_model_snr  pl_orbsmax  pl_rade       pl_masse    pl_dens  pl_eqt  \\\n",
            "0           29.8    0.054618    24.12  130255.485759  51.176725  1166.0   \n",
            "1          183.6    0.091935     7.73    1933.143651  23.074591   812.0   \n",
            "2           23.9    0.048915    23.51  118477.185245  50.267260  1083.0   \n",
            "3          151.8    0.352535    22.89  107322.166934  49.335602   291.0   \n",
            "4           37.2    0.142161     1.96      12.060004   8.830547   621.0   \n",
            "\n",
            "                                     lightcurve_file  \n",
            "0  /content/drive/MyDrive/Data/kepler_3541800_lig...  \n",
            "1  /content/drive/MyDrive/Data/kepler_3115833_lig...  \n",
            "2  /content/drive/MyDrive/Data/kepler_4673628_lig...  \n",
            "3  /content/drive/MyDrive/Data/kepler_4055092_lig...  \n",
            "4  /content/drive/MyDrive/Data/kepler_3440118_lig...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Your lightcurve preprocessing function\n",
        "def preprocess_lightcurve(csv_file, seq_length=1024):\n",
        "    df = pd.read_csv(csv_file)\n",
        "    df = df[['time_bjd', 'flux', 'flux_err']].dropna()\n",
        "    df = df.sort_values('time_bjd')\n",
        "\n",
        "    flux = df['flux'].values\n",
        "    flux_err = df['flux_err'].values\n",
        "\n",
        "    # Normalize flux\n",
        "    flux_mean = np.mean(flux)\n",
        "    flux_std = np.std(flux)\n",
        "    flux_norm = (flux - flux_mean) / flux_std\n",
        "\n",
        "    # Normalize flux_error\n",
        "    flux_err_norm = flux_err / np.std(flux_err)\n",
        "\n",
        "    # Pad or truncate to fixed length\n",
        "    if len(flux_norm) < seq_length:\n",
        "        pad_width = seq_length - len(flux_norm)\n",
        "        flux_norm = np.pad(flux_norm, (0, pad_width), 'constant')\n",
        "        flux_err_norm = np.pad(flux_err_norm, (0, pad_width), 'constant')\n",
        "    else:\n",
        "        flux_norm = flux_norm[:seq_length]\n",
        "        flux_err_norm = flux_err_norm[:seq_length]\n",
        "\n",
        "    # Return only flux (1 channel)\n",
        "    return flux_norm.astype(np.float32)[..., np.newaxis]\n",
        "\n",
        "# Load label CSV\n",
        "labels_df = pd.read_csv('/content/labels_existence.csv')\n",
        "\n",
        "# Prepare arrays\n",
        "X_list = []\n",
        "y_list = []\n",
        "\n",
        "print(\"Preprocessing lightcurves...\")\n",
        "for idx, row in tqdm(labels_df.iterrows(), total=len(labels_df)):\n",
        "    lc_path = row['lightcurve_file']\n",
        "    if os.path.exists(lc_path):\n",
        "        flux_array = preprocess_lightcurve(lc_path, seq_length=1024)\n",
        "        X_list.append(flux_array)\n",
        "        y_list.append(row['target'])\n",
        "    else:\n",
        "        print(f\"File not found: {lc_path}\")\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "X = np.array(X_list)          # shape: (num_samples, 1024, 1)\n",
        "y = np.array(y_list)          # shape: (num_samples,)\n",
        "\n",
        "print(\"Done!\")\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwqpriAeHoEY",
        "outputId": "98dfb550-3020-4bd6-dd26-233504577988"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing lightcurves...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5190/5190 [38:20<00:00,  2.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!\n",
            "X shape: (5190, 1024, 1)\n",
            "y shape: (5190,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Build 1D CNN\n",
        "model = Sequential([\n",
        "    Conv1D(32, kernel_size=5, activation='relu', input_shape=(1024,1)),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv1D(64, kernel_size=5, activation='relu'),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv1D(128, kernel_size=5, activation='relu'),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(1, activation='sigmoid')  # Binary classification\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "y2Utz8laIEa_",
        "outputId": "7314e55d-b76a-4c8a-dfc5-d958a2bd7e6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1020\u001b[0m, \u001b[38;5;34m32\u001b[0m)       â”‚           \u001b[38;5;34m192\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m510\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m510\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m506\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m10,304\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m253\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m253\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m249\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚        \u001b[38;5;34m41,088\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m124\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_2           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m124\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (\u001b[38;5;33mFlatten\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15872\u001b[0m)          â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚     \u001b[38;5;34m2,031,744\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚           \u001b[38;5;34m129\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1020</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">510</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">510</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">506</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">253</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">253</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">249</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">124</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_2           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">124</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15872</span>)          â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,031,744</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,084,353\u001b[0m (7.95 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,084,353</span> (7.95 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,083,905\u001b[0m (7.95 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,083,905</span> (7.95 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "# Split data\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.1, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"Train shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Validation shape:\", X_val.shape, y_val.shape)\n",
        "\n",
        "# Callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6),\n",
        "    ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss')\n",
        "]\n",
        "\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    callbacks=callbacks\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rayc1REQITme",
        "outputId": "125585ca-0936-4cc9-d8fe-f2c09449e56b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (4671, 1024, 1) (4671,)\n",
            "Validation shape: (519, 1024, 1) (519,)\n",
            "Epoch 1/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.5563 - loss: 2.3224"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 187ms/step - accuracy: 0.5565 - loss: 2.3197 - val_accuracy: 0.5356 - val_loss: 0.6606 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 188ms/step - accuracy: 0.6706 - loss: 0.7558 - val_accuracy: 0.5819 - val_loss: 0.6828 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 204ms/step - accuracy: 0.7542 - loss: 0.5032 - val_accuracy: 0.6301 - val_loss: 0.7133 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 263ms/step - accuracy: 0.8403 - loss: 0.3604 - val_accuracy: 0.6513 - val_loss: 0.8200 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 191ms/step - accuracy: 0.8809 - loss: 0.2661 - val_accuracy: 0.6493 - val_loss: 0.7981 - learning_rate: 5.0000e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 179ms/step - accuracy: 0.9334 - loss: 0.1736 - val_accuracy: 0.6397 - val_loss: 0.8857 - learning_rate: 5.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, BatchNormalization\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "# -------------------------------\n",
        "# Model architecture\n",
        "# -------------------------------\n",
        "def build_cnn_model(input_shape=(1024,1)):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "\n",
        "        Conv1D(32, 5, activation='relu', padding='same'),\n",
        "        MaxPooling1D(2),\n",
        "        BatchNormalization(),\n",
        "\n",
        "        Conv1D(64, 5, activation='relu', padding='same'),\n",
        "        MaxPooling1D(2),\n",
        "        BatchNormalization(),\n",
        "\n",
        "        Conv1D(128, 3, activation='relu', padding='same'),\n",
        "        MaxPooling1D(2),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),  # helps prevent overfitting\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.4),\n",
        "        Dense(1, activation='sigmoid')  # output for existence (0/1)\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# -------------------------------\n",
        "# Callbacks\n",
        "# -------------------------------\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=8,  # give more chance before stopping\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=3,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'best_model.keras',\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# Build and train model\n",
        "# -------------------------------\n",
        "model = build_cnn_model(input_shape=(1024,1))\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stop, reduce_lr, checkpoint],\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jHBumxZtZ-6f",
        "outputId": "5bdf42db-5fda-44da-f79f-291f322b5955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m32\u001b[0m)       â”‚           \u001b[38;5;34m192\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling1d_3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_3           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m10,304\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling1d_4 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_4           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚        \u001b[38;5;34m24,704\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling1d_5 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_5           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16384\u001b[0m)          â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚     \u001b[38;5;34m2,097,280\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚           \u001b[38;5;34m129\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_3           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_4           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization_5           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16384</span>)          â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,280</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,133,505\u001b[0m (8.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,133,505</span> (8.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,133,057\u001b[0m (8.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,133,057</span> (8.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.5592 - loss: 2.1409\n",
            "Epoch 1: val_loss improved from inf to 0.68704, saving model to best_model.keras\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 182ms/step - accuracy: 0.5593 - loss: 2.1391 - val_accuracy: 0.5202 - val_loss: 0.6870 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.6618 - loss: 0.8626\n",
            "Epoch 2: val_loss did not improve from 0.68704\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 169ms/step - accuracy: 0.6617 - loss: 0.8624 - val_accuracy: 0.4952 - val_loss: 0.6962 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.7094 - loss: 0.5739\n",
            "Epoch 3: val_loss improved from 0.68704 to 0.66148, saving model to best_model.keras\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 167ms/step - accuracy: 0.7095 - loss: 0.5738 - val_accuracy: 0.6050 - val_loss: 0.6615 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.7780 - loss: 0.4581\n",
            "Epoch 4: val_loss did not improve from 0.66148\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 182ms/step - accuracy: 0.7780 - loss: 0.4580 - val_accuracy: 0.6647 - val_loss: 0.7366 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.8376 - loss: 0.3598\n",
            "Epoch 5: val_loss did not improve from 0.66148\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 183ms/step - accuracy: 0.8376 - loss: 0.3599 - val_accuracy: 0.6551 - val_loss: 0.7648 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.8741 - loss: 0.3011\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 6: val_loss did not improve from 0.66148\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 199ms/step - accuracy: 0.8740 - loss: 0.3013 - val_accuracy: 0.6513 - val_loss: 0.8450 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.8989 - loss: 0.2638\n",
            "Epoch 7: val_loss did not improve from 0.66148\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 172ms/step - accuracy: 0.8989 - loss: 0.2637 - val_accuracy: 0.6532 - val_loss: 0.8441 - learning_rate: 5.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.9327 - loss: 0.1958\n",
            "Epoch 8: val_loss did not improve from 0.66148\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 175ms/step - accuracy: 0.9327 - loss: 0.1958 - val_accuracy: 0.6455 - val_loss: 0.9098 - learning_rate: 5.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9360 - loss: 0.1873\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.66148\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 183ms/step - accuracy: 0.9360 - loss: 0.1874 - val_accuracy: 0.6551 - val_loss: 0.9101 - learning_rate: 5.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9386 - loss: 0.1670\n",
            "Epoch 10: val_loss did not improve from 0.66148\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 186ms/step - accuracy: 0.9387 - loss: 0.1669 - val_accuracy: 0.6397 - val_loss: 0.9457 - learning_rate: 2.5000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.9522 - loss: 0.1271\n",
            "Epoch 11: val_loss did not improve from 0.66148\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 189ms/step - accuracy: 0.9522 - loss: 0.1271 - val_accuracy: 0.6532 - val_loss: 0.9708 - learning_rate: 2.5000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_light_model(input_shape=(1024,1)):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "\n",
        "        Conv1D(16, 5, activation='relu', padding='same'),\n",
        "        MaxPooling1D(2),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.4),\n",
        "\n",
        "        Conv1D(32, 3, activation='relu', padding='same'),\n",
        "        MaxPooling1D(2),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.4),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "p6COUbUTcLaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_light_model(input_shape=(1024,1))\n",
        "\n",
        "# Split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)\n",
        "\n",
        "# Callbacks\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"best_model.keras\", monitor=\"val_loss\", save_best_only=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-5)\n",
        "early_stop = EarlyStopping(monitor=\"val_loss\", patience=6, restore_best_weights=True)\n",
        "\n",
        "# Train\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    callbacks=[checkpoint, reduce_lr, early_stop]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nniHnfQBcQzg",
        "outputId": "1e48f921-2606-48d4-bb2d-9d8d77401e43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.5397 - loss: 1.3472 - val_accuracy: 0.5318 - val_loss: 0.6893 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 70ms/step - accuracy: 0.6114 - loss: 0.7809 - val_accuracy: 0.4586 - val_loss: 0.6933 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 67ms/step - accuracy: 0.6403 - loss: 0.6277 - val_accuracy: 0.5549 - val_loss: 0.6827 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 55ms/step - accuracy: 0.6404 - loss: 0.6132 - val_accuracy: 0.5299 - val_loss: 0.6855 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 69ms/step - accuracy: 0.6627 - loss: 0.5951 - val_accuracy: 0.5877 - val_loss: 0.6449 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 71ms/step - accuracy: 0.6869 - loss: 0.5687 - val_accuracy: 0.5742 - val_loss: 0.6437 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 64ms/step - accuracy: 0.6977 - loss: 0.5574 - val_accuracy: 0.6146 - val_loss: 0.6247 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 119ms/step - accuracy: 0.7146 - loss: 0.5426 - val_accuracy: 0.5857 - val_loss: 0.6685 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 70ms/step - accuracy: 0.7318 - loss: 0.5267 - val_accuracy: 0.6185 - val_loss: 0.6232 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 69ms/step - accuracy: 0.7277 - loss: 0.5160 - val_accuracy: 0.6127 - val_loss: 0.6525 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 68ms/step - accuracy: 0.7477 - loss: 0.4991 - val_accuracy: 0.6146 - val_loss: 0.6417 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 69ms/step - accuracy: 0.7554 - loss: 0.4867 - val_accuracy: 0.6224 - val_loss: 0.6487 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - accuracy: 0.7678 - loss: 0.4805 - val_accuracy: 0.6204 - val_loss: 0.6475 - learning_rate: 5.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 68ms/step - accuracy: 0.7634 - loss: 0.4491 - val_accuracy: 0.6243 - val_loss: 0.6481 - learning_rate: 5.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step - accuracy: 0.7825 - loss: 0.4430 - val_accuracy: 0.6320 - val_loss: 0.6359 - learning_rate: 5.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ----------------------------\n",
        "# 1ï¸âƒ£ Lightcurve preprocessing\n",
        "# ----------------------------\n",
        "def preprocess_lightcurve(csv_file, seq_length=1024):\n",
        "    \"\"\"\n",
        "    Load and normalize a lightcurve CSV for CNN input.\n",
        "    Returns a flux array of shape (seq_length, 1)\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(csv_file)[['time_bjd','flux','flux_err']].dropna()\n",
        "    df = df.sort_values('time_bjd')\n",
        "\n",
        "    flux = df['flux'].values\n",
        "    flux_err = df['flux_err'].values\n",
        "\n",
        "    # Normalize flux\n",
        "    flux_norm = (flux - np.mean(flux)) / np.std(flux)\n",
        "    flux_err_norm = flux_err / np.std(flux_err)\n",
        "\n",
        "    # Pad or truncate\n",
        "    if len(flux_norm) < seq_length:\n",
        "        pad_width = seq_length - len(flux_norm)\n",
        "        flux_norm = np.pad(flux_norm, (0, pad_width), 'constant')\n",
        "    else:\n",
        "        flux_norm = flux_norm[:seq_length]\n",
        "\n",
        "    return flux_norm.astype(np.float32)[..., np.newaxis]\n",
        "\n",
        "# ----------------------------\n",
        "# 2ï¸âƒ£ Load labels\n",
        "# ----------------------------\n",
        "labels_file = '/content/labels_existence.csv'\n",
        "labels_df = pd.read_csv(labels_file)\n",
        "\n",
        "# Preprocess all lightcurves\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "print(\"Preprocessing lightcurves...\")\n",
        "for idx, row in tqdm(labels_df.iterrows(), total=len(labels_df)):\n",
        "    csv_path = row['lightcurve_file']\n",
        "    X.append(preprocess_lightcurve(csv_path))\n",
        "    y.append(row['target'])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
        "\n",
        "# ----------------------------\n",
        "# 3ï¸âƒ£ Train/Validation split\n",
        "# ----------------------------\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.1, random_state=42, stratify=y\n",
        ")\n",
        "print(f\"Train shape: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Validation shape: {X_val.shape}, {y_val.shape}\")\n",
        "\n",
        "# ----------------------------\n",
        "# 4ï¸âƒ£ Build CNN model\n",
        "# ----------------------------\n",
        "def build_light_model(input_shape=(1024,1)):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "\n",
        "        Conv1D(16, kernel_size=5, activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(2),\n",
        "        Dropout(0.4),\n",
        "\n",
        "        Conv1D(32, kernel_size=3, activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(2),\n",
        "        Dropout(0.4),\n",
        "\n",
        "        Conv1D(64, kernel_size=3, activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(2),\n",
        "        Dropout(0.4),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# ----------------------------\n",
        "# 5ï¸âƒ£ Callbacks\n",
        "# ----------------------------\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)\n",
        "checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, verbose=1)\n",
        "\n",
        "# ----------------------------\n",
        "# 6ï¸âƒ£ Train model\n",
        "# ----------------------------\n",
        "model = build_light_model()\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stop, reduce_lr, checkpoint]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJH3H2Gtd0jt",
        "outputId": "8ac59aeb-855b-4d33-a2d2-ccdf07bf1932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing lightcurves...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5190/5190 [44:42<00:00,  1.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (5190, 1024, 1), y shape: (5190,)\n",
            "Train shape: (4671, 1024, 1), (4671,)\n",
            "Validation shape: (519, 1024, 1), (519,)\n",
            "Epoch 1/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.5319 - loss: 1.0256\n",
            "Epoch 1: val_loss improved from inf to 5.91266, saving model to best_model.keras\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 101ms/step - accuracy: 0.5321 - loss: 1.0241 - val_accuracy: 0.4663 - val_loss: 5.9127 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.5958 - loss: 0.6442\n",
            "Epoch 2: val_loss did not improve from 5.91266\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 97ms/step - accuracy: 0.5959 - loss: 0.6442 - val_accuracy: 0.4740 - val_loss: 6.4814 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.6116 - loss: 0.6245\n",
            "Epoch 3: val_loss improved from 5.91266 to 3.78017, saving model to best_model.keras\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 166ms/step - accuracy: 0.6116 - loss: 0.6245 - val_accuracy: 0.5222 - val_loss: 3.7802 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.6334 - loss: 0.6064\n",
            "Epoch 4: val_loss improved from 3.78017 to 2.57045, saving model to best_model.keras\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 115ms/step - accuracy: 0.6333 - loss: 0.6065 - val_accuracy: 0.5549 - val_loss: 2.5704 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.6238 - loss: 0.6015\n",
            "Epoch 5: val_loss did not improve from 2.57045\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 92ms/step - accuracy: 0.6238 - loss: 0.6015 - val_accuracy: 0.5472 - val_loss: 2.6574 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.6253 - loss: 0.5995\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 6: val_loss did not improve from 2.57045\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 97ms/step - accuracy: 0.6252 - loss: 0.5995 - val_accuracy: 0.5588 - val_loss: 2.6588 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.6221 - loss: 0.6053\n",
            "Epoch 7: val_loss did not improve from 2.57045\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 97ms/step - accuracy: 0.6221 - loss: 0.6052 - val_accuracy: 0.5626 - val_loss: 2.5737 - learning_rate: 5.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.6321 - loss: 0.5883\n",
            "Epoch 8: val_loss improved from 2.57045 to 2.50292, saving model to best_model.keras\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 98ms/step - accuracy: 0.6321 - loss: 0.5883 - val_accuracy: 0.5568 - val_loss: 2.5029 - learning_rate: 5.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.6313 - loss: 0.5904\n",
            "Epoch 9: val_loss did not improve from 2.50292\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 97ms/step - accuracy: 0.6313 - loss: 0.5903 - val_accuracy: 0.5588 - val_loss: 2.6070 - learning_rate: 5.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.6390 - loss: 0.5865\n",
            "Epoch 10: val_loss improved from 2.50292 to 2.46055, saving model to best_model.keras\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 99ms/step - accuracy: 0.6390 - loss: 0.5865 - val_accuracy: 0.5568 - val_loss: 2.4606 - learning_rate: 5.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.6450 - loss: 0.5678\n",
            "Epoch 11: val_loss did not improve from 2.46055\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 99ms/step - accuracy: 0.6450 - loss: 0.5678 - val_accuracy: 0.5511 - val_loss: 2.4786 - learning_rate: 5.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.6444 - loss: 0.5781\n",
            "Epoch 12: val_loss improved from 2.46055 to 2.18662, saving model to best_model.keras\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 100ms/step - accuracy: 0.6444 - loss: 0.5781 - val_accuracy: 0.5800 - val_loss: 2.1866 - learning_rate: 5.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.6339 - loss: 0.5751\n",
            "Epoch 13: val_loss did not improve from 2.18662\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 101ms/step - accuracy: 0.6339 - loss: 0.5751 - val_accuracy: 0.5742 - val_loss: 2.4639 - learning_rate: 5.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.6452 - loss: 0.5684\n",
            "Epoch 14: val_loss improved from 2.18662 to 2.08260, saving model to best_model.keras\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 104ms/step - accuracy: 0.6452 - loss: 0.5684 - val_accuracy: 0.5857 - val_loss: 2.0826 - learning_rate: 5.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.6612 - loss: 0.5622\n",
            "Epoch 15: val_loss improved from 2.08260 to 1.96798, saving model to best_model.keras\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 101ms/step - accuracy: 0.6612 - loss: 0.5623 - val_accuracy: 0.5973 - val_loss: 1.9680 - learning_rate: 5.0000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.6472 - loss: 0.5634\n",
            "Epoch 16: val_loss did not improve from 1.96798\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 99ms/step - accuracy: 0.6472 - loss: 0.5635 - val_accuracy: 0.5800 - val_loss: 2.0217 - learning_rate: 5.0000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.6533 - loss: 0.5524\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 17: val_loss did not improve from 1.96798\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 99ms/step - accuracy: 0.6533 - loss: 0.5525 - val_accuracy: 0.5877 - val_loss: 2.4965 - learning_rate: 5.0000e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.6463 - loss: 0.5520\n",
            "Epoch 18: val_loss did not improve from 1.96798\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 98ms/step - accuracy: 0.6463 - loss: 0.5520 - val_accuracy: 0.5761 - val_loss: 2.1981 - learning_rate: 2.5000e-04\n",
            "Epoch 19/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.6516 - loss: 0.5469\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 19: val_loss did not improve from 1.96798\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 110ms/step - accuracy: 0.6517 - loss: 0.5469 - val_accuracy: 0.5800 - val_loss: 2.0880 - learning_rate: 2.5000e-04\n",
            "Epoch 20/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.6667 - loss: 0.5450\n",
            "Epoch 20: val_loss did not improve from 1.96798\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 100ms/step - accuracy: 0.6666 - loss: 0.5450 - val_accuracy: 0.5877 - val_loss: 2.1178 - learning_rate: 1.2500e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
        "import tensorflow as tf\n",
        "\n",
        "def build_light_model(input_shape=(1024,1)):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "\n",
        "        Conv1D(32, 5, activation='relu', padding='same'),\n",
        "        MaxPooling1D(2),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Conv1D(64, 3, activation='relu', padding='same'),\n",
        "        MaxPooling1D(2),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Conv1D(128, 3, activation='relu', padding='same'),\n",
        "        MaxPooling1D(2),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.4),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "l6HaRcvop2N3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=1e-6),\n",
        "    ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    callbacks=callbacks\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XY41o5g8qCyA",
        "outputId": "e39aa150-8f0d-4f8d-fec0-f4e627b82e9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 100ms/step - accuracy: 0.6524 - loss: 0.5561 - val_accuracy: 0.5934 - val_loss: 1.8175 - learning_rate: 1.2500e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 95ms/step - accuracy: 0.6557 - loss: 0.5525 - val_accuracy: 0.5954 - val_loss: 1.9292 - learning_rate: 1.2500e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 92ms/step - accuracy: 0.6489 - loss: 0.5481 - val_accuracy: 0.6012 - val_loss: 1.9863 - learning_rate: 1.2500e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 93ms/step - accuracy: 0.6605 - loss: 0.5449 - val_accuracy: 0.5934 - val_loss: 2.0149 - learning_rate: 1.2500e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 115ms/step - accuracy: 0.6470 - loss: 0.5589 - val_accuracy: 0.5838 - val_loss: 2.1135 - learning_rate: 1.2500e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 97ms/step - accuracy: 0.6858 - loss: 0.5350 - val_accuracy: 0.5896 - val_loss: 2.0291 - learning_rate: 6.2500e-05\n",
            "Epoch 7/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 97ms/step - accuracy: 0.6662 - loss: 0.5421 - val_accuracy: 0.5915 - val_loss: 2.0775 - learning_rate: 6.2500e-05\n",
            "Epoch 8/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 97ms/step - accuracy: 0.6525 - loss: 0.5578 - val_accuracy: 0.5838 - val_loss: 2.0880 - learning_rate: 6.2500e-05\n",
            "Epoch 9/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 157ms/step - accuracy: 0.6517 - loss: 0.5362 - val_accuracy: 0.5838 - val_loss: 2.0846 - learning_rate: 6.2500e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "\n",
        "def build_light_model(input_shape=(1024,1)):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "\n",
        "        Conv1D(16, 5, activation='relu', padding='same'),\n",
        "        MaxPooling1D(2),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Conv1D(32, 3, activation='relu', padding='same'),\n",
        "        MaxPooling1D(2),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Conv1D(64, 3, activation='relu', padding='same'),\n",
        "        MaxPooling1D(2),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.4),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6),\n",
        "    ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)\n",
        "]\n",
        "\n",
        "# Example training call\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    callbacks=callbacks\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-NUejZVq739",
        "outputId": "d8bfc4f0-7427-467e-fa05-82b86b7a5a1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 93ms/step - accuracy: 0.6436 - loss: 0.5554 - val_accuracy: 0.5857 - val_loss: 1.9770 - learning_rate: 3.1250e-05\n",
            "Epoch 2/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 106ms/step - accuracy: 0.6557 - loss: 0.5537 - val_accuracy: 0.5838 - val_loss: 2.0707 - learning_rate: 3.1250e-05\n",
            "Epoch 3/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 96ms/step - accuracy: 0.6547 - loss: 0.5530 - val_accuracy: 0.5800 - val_loss: 2.0845 - learning_rate: 3.1250e-05\n",
            "Epoch 4/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 97ms/step - accuracy: 0.6567 - loss: 0.5468 - val_accuracy: 0.5896 - val_loss: 2.0524 - learning_rate: 3.1250e-05\n",
            "Epoch 5/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 91ms/step - accuracy: 0.6573 - loss: 0.5530 - val_accuracy: 0.5877 - val_loss: 2.0596 - learning_rate: 1.5625e-05\n",
            "Epoch 6/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 95ms/step - accuracy: 0.6624 - loss: 0.5530 - val_accuracy: 0.5838 - val_loss: 2.1368 - learning_rate: 1.5625e-05\n",
            "Epoch 7/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 96ms/step - accuracy: 0.6591 - loss: 0.5518 - val_accuracy: 0.5857 - val_loss: 2.1377 - learning_rate: 1.5625e-05\n",
            "Epoch 8/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 96ms/step - accuracy: 0.6531 - loss: 0.5501 - val_accuracy: 0.5877 - val_loss: 2.1198 - learning_rate: 7.8125e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train / np.max(np.abs(X_train), axis=1, keepdims=True)\n",
        "X_val = X_val / np.max(np.abs(X_val), axis=1, keepdims=True)\n"
      ],
      "metadata": {
        "id": "YkYy0O_msIcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "\n",
        "def build_light_model(input_shape=(1024,1)):\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "\n",
        "        Conv1D(16, 5, activation='relu', padding='same'),\n",
        "        MaxPooling1D(2),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Conv1D(32, 3, activation='relu', padding='same'),\n",
        "        MaxPooling1D(2),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Conv1D(64, 3, activation='relu', padding='same'),\n",
        "        MaxPooling1D(2),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.4),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6),\n",
        "    ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)\n",
        "]\n",
        "\n",
        "# Example training\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    callbacks=callbacks,\n",
        "    shuffle=True\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhH5AK-6sNNY",
        "outputId": "ad163260-07c2-4007-da90-c290b26090d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 97ms/step - accuracy: 0.5935 - loss: 0.6259 - val_accuracy: 0.5279 - val_loss: 4.4832 - learning_rate: 7.8125e-06\n",
            "Epoch 2/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 97ms/step - accuracy: 0.5869 - loss: 0.6312 - val_accuracy: 0.5549 - val_loss: 2.7669 - learning_rate: 7.8125e-06\n",
            "Epoch 3/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 97ms/step - accuracy: 0.5994 - loss: 0.6065 - val_accuracy: 0.5665 - val_loss: 2.0750 - learning_rate: 7.8125e-06\n",
            "Epoch 4/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 97ms/step - accuracy: 0.5929 - loss: 0.6083 - val_accuracy: 0.5742 - val_loss: 1.8734 - learning_rate: 7.8125e-06\n",
            "Epoch 5/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 97ms/step - accuracy: 0.5913 - loss: 0.6038 - val_accuracy: 0.5742 - val_loss: 1.7934 - learning_rate: 7.8125e-06\n",
            "Epoch 6/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 95ms/step - accuracy: 0.5858 - loss: 0.6082 - val_accuracy: 0.5742 - val_loss: 1.7405 - learning_rate: 7.8125e-06\n",
            "Epoch 7/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 94ms/step - accuracy: 0.5958 - loss: 0.5984 - val_accuracy: 0.5761 - val_loss: 1.7291 - learning_rate: 7.8125e-06\n",
            "Epoch 8/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 97ms/step - accuracy: 0.6055 - loss: 0.5957 - val_accuracy: 0.5761 - val_loss: 1.7150 - learning_rate: 7.8125e-06\n",
            "Epoch 9/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 101ms/step - accuracy: 0.6091 - loss: 0.5924 - val_accuracy: 0.5780 - val_loss: 1.6772 - learning_rate: 7.8125e-06\n",
            "Epoch 10/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 133ms/step - accuracy: 0.5996 - loss: 0.6005 - val_accuracy: 0.5761 - val_loss: 1.6773 - learning_rate: 7.8125e-06\n",
            "Epoch 11/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 98ms/step - accuracy: 0.6155 - loss: 0.5854 - val_accuracy: 0.5742 - val_loss: 1.6879 - learning_rate: 7.8125e-06\n",
            "Epoch 12/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 99ms/step - accuracy: 0.5928 - loss: 0.5999 - val_accuracy: 0.5723 - val_loss: 1.6621 - learning_rate: 7.8125e-06\n",
            "Epoch 13/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 104ms/step - accuracy: 0.5948 - loss: 0.6050 - val_accuracy: 0.5742 - val_loss: 1.6647 - learning_rate: 7.8125e-06\n",
            "Epoch 14/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 96ms/step - accuracy: 0.6028 - loss: 0.5925 - val_accuracy: 0.5723 - val_loss: 1.6646 - learning_rate: 7.8125e-06\n",
            "Epoch 15/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 103ms/step - accuracy: 0.5770 - loss: 0.6047 - val_accuracy: 0.5723 - val_loss: 1.6456 - learning_rate: 7.8125e-06\n",
            "Epoch 16/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 99ms/step - accuracy: 0.5961 - loss: 0.6038 - val_accuracy: 0.5723 - val_loss: 1.6561 - learning_rate: 7.8125e-06\n",
            "Epoch 17/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 97ms/step - accuracy: 0.6050 - loss: 0.5934 - val_accuracy: 0.5723 - val_loss: 1.6620 - learning_rate: 7.8125e-06\n",
            "Epoch 18/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 98ms/step - accuracy: 0.6059 - loss: 0.5990 - val_accuracy: 0.5703 - val_loss: 1.6629 - learning_rate: 7.8125e-06\n",
            "Epoch 19/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 97ms/step - accuracy: 0.6107 - loss: 0.6021 - val_accuracy: 0.5703 - val_loss: 1.6602 - learning_rate: 3.9063e-06\n",
            "Epoch 20/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 93ms/step - accuracy: 0.6005 - loss: 0.5847 - val_accuracy: 0.5703 - val_loss: 1.6532 - learning_rate: 3.9063e-06\n",
            "Epoch 21/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 92ms/step - accuracy: 0.6087 - loss: 0.5971 - val_accuracy: 0.5723 - val_loss: 1.6534 - learning_rate: 3.9063e-06\n",
            "Epoch 22/30\n",
            "\u001b[1m146/146\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 93ms/step - accuracy: 0.5961 - loss: 0.5946 - val_accuracy: 0.5723 - val_loss: 1.6487 - learning_rate: 1.9531e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# IMPORTS\n",
        "# -------------------------------\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report\n",
        "import lightgbm as lgb\n",
        "from lightgbm import early_stopping, log_evaluation\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -------------------------------\n",
        "# PARAMETERS\n",
        "# -------------------------------\n",
        "LABEL_FILE = \"/content/labels_existence.csv\"\n",
        "LIGHTCURVE_DIR = \"/content/drive/MyDrive/Data\"\n",
        "\n",
        "# -------------------------------\n",
        "# FEATURE EXTRACTION FUNCTION\n",
        "# -------------------------------\n",
        "def extract_features(lc_file):\n",
        "    \"\"\"\n",
        "    Reads a lightcurve CSV and returns statistical features.\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(lc_file)\n",
        "\n",
        "    flux = df['flux'].values\n",
        "    flux_err = df['flux_err'].values\n",
        "\n",
        "    features = {}\n",
        "    features['flux_mean'] = np.mean(flux)\n",
        "    features['flux_std'] = np.std(flux)\n",
        "    features['flux_median'] = np.median(flux)\n",
        "    features['flux_min'] = np.min(flux)\n",
        "    features['flux_max'] = np.max(flux)\n",
        "    features['flux_skew'] = pd.Series(flux).skew()\n",
        "    features['flux_kurt'] = pd.Series(flux).kurt()\n",
        "\n",
        "    # Estimate dip features (simple transit proxy)\n",
        "    flux_diff = features['flux_mean'] - flux\n",
        "    features['dip_max'] = np.max(flux_diff)\n",
        "    features['dip_mean'] = np.mean(flux_diff)\n",
        "    features['dip_std'] = np.std(flux_diff)\n",
        "\n",
        "    return features\n",
        "\n",
        "# -------------------------------\n",
        "# LOAD DATA AND EXTRACT FEATURES\n",
        "# -------------------------------\n",
        "labels_df = pd.read_csv(LABEL_FILE)\n",
        "\n",
        "feature_list = []\n",
        "for idx, row in labels_df.iterrows():\n",
        "    lc_file = row['lightcurve_file']\n",
        "    if os.path.exists(lc_file):\n",
        "        feats = extract_features(lc_file)\n",
        "        feature_list.append(feats)\n",
        "    else:\n",
        "        print(f\"File missing: {lc_file}\")\n",
        "\n",
        "X = pd.DataFrame(feature_list)\n",
        "y = labels_df['target'].values\n",
        "\n",
        "print(\"Feature matrix shape:\", X.shape)\n",
        "print(\"Target vector shape:\", y.shape)\n",
        "\n",
        "# -------------------------------\n",
        "# TRAIN-TEST SPLIT\n",
        "# -------------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.1, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# FEATURE SCALING\n",
        "# -------------------------------\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# -------------------------------\n",
        "# LIGHTGBM MODEL\n",
        "# -------------------------------\n",
        "model = lgb.LGBMClassifier(\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train with callbacks for early stopping & logging\n",
        "model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    eval_set=[(X_test_scaled, y_test)],\n",
        "    eval_metric='binary_logloss',\n",
        "    callbacks=[\n",
        "        early_stopping(stopping_rounds=20),\n",
        "        log_evaluation(period=10)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# EVALUATION\n",
        "# -------------------------------\n",
        "y_pred_proba = model.predict_proba(X_test_scaled)[:,1]  # probability\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "roc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n",
        "print(f\"ROC AUC Score: {roc:.4f}\")\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.imshow(cm, cmap='Blues')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.colorbar()\n",
        "plt.xticks([0,1], [\"No Planet\",\"Planet\"])\n",
        "plt.yticks([0,1], [\"No Planet\",\"Planet\"])\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        plt.text(j,i,cm[i,j],ha='center',va='center',color='red',fontsize=16)\n",
        "plt.show()\n",
        "\n",
        "# -------------------------------\n",
        "# SAVE MODEL AND SCALER\n",
        "# -------------------------------\n",
        "import joblib\n",
        "joblib.dump(model, \"lgb_exoplanet_model.pkl\")\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "\n",
        "print(\"Model and scaler saved. Ready for inference!\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "loOY-6LDwLJ0",
        "outputId": "1f920977-e1f3-436f-887e-e1378b240ac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature matrix shape: (5190, 10)\n",
            "Target vector shape: (5190,)\n",
            "[LightGBM] [Info] Number of positive: 2182, number of negative: 2489\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000973 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2295\n",
            "[LightGBM] [Info] Number of data points in the train set: 4671, number of used features: 9\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.467138 -> initscore=-0.131639\n",
            "[LightGBM] [Info] Start training from score -0.131639\n",
            "Training until validation scores don't improve for 20 rounds\n",
            "[10]\tvalid_0's binary_logloss: 0.614042\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[20]\tvalid_0's binary_logloss: 0.580847\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[30]\tvalid_0's binary_logloss: 0.561624\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[40]\tvalid_0's binary_logloss: 0.55398\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[50]\tvalid_0's binary_logloss: 0.550588\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[60]\tvalid_0's binary_logloss: 0.549744\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[70]\tvalid_0's binary_logloss: 0.547861\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[80]\tvalid_0's binary_logloss: 0.546099\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[90]\tvalid_0's binary_logloss: 0.545262\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[100]\tvalid_0's binary_logloss: 0.544881\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[110]\tvalid_0's binary_logloss: 0.544497\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[120]\tvalid_0's binary_logloss: 0.543512\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[130]\tvalid_0's binary_logloss: 0.544234\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[140]\tvalid_0's binary_logloss: 0.544082\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Early stopping, best iteration is:\n",
            "[122]\tvalid_0's binary_logloss: 0.543034\n",
            "Test Accuracy: 0.6898\n",
            "ROC AUC Score: 0.7770\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.66      0.69       277\n",
            "           1       0.65      0.73      0.69       242\n",
            "\n",
            "    accuracy                           0.69       519\n",
            "   macro avg       0.69      0.69      0.69       519\n",
            "weighted avg       0.69      0.69      0.69       519\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and scaler saved. Ready for inference!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "# Load trained model\n",
        "model = joblib.load(\"/content/lgb_exoplanet_model.pkl\")  # or your Drive path\n",
        "print(\"âœ… Model loaded\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sABHE7G1HhLl",
        "outputId": "e64fdce4-7611-4f70-bb8a-381f126acb8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/kepler_10797460_lightcurve.csv'\n",
        "def extract_features_from_lightcurve(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    flux = df['flux'].values\n",
        "\n",
        "    # Basic statistical features (same as training)\n",
        "    features = {\n",
        "        'mean_flux': np.mean(flux),\n",
        "        'std_flux': np.std(flux),\n",
        "        'min_flux': np.min(flux),\n",
        "        'max_flux': np.max(flux),\n",
        "        'median_flux': np.median(flux),\n",
        "        'range_flux': np.max(flux) - np.min(flux),\n",
        "        'q25_flux': np.percentile(flux, 25),\n",
        "        'q75_flux': np.percentile(flux, 75),\n",
        "        'skew_flux': pd.Series(flux).skew(),\n",
        "        'kurt_flux': pd.Series(flux).kurt()\n",
        "    }\n",
        "\n",
        "    return np.array(list(features.values())).reshape(1, -1)\n"
      ],
      "metadata": {
        "id": "UpoNuiKzHpD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to new lightcurve CSV file\n",
        "new_file = \"/content/kepler_10797460_lightcurve.csv\"\n",
        "\n",
        "# Extract features\n",
        "X_new = extract_features_from_lightcurve(new_file)\n",
        "\n",
        "# Predict probability\n",
        "prob = model.predict_proba(X_new)[0][1]  # Probability for class '1'\n",
        "pred = model.predict(X_new)[0]           # 0 or 1 prediction\n",
        "\n",
        "print(f\"ğŸª Exoplanet Existence Probability: {prob*100:.2f}%\")\n",
        "print(f\"Predicted Class: {pred} (1 = Exoplanet, 0 = No Exoplanet)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNIoe7FCIG9d",
        "outputId": "1d15cf54-5e4a-4d78-8bd0-12277c4dc3e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸª Exoplanet Existence Probability: 85.68%\n",
            "Predicted Class: 1 (1 = Exoplanet, 0 = No Exoplanet)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# IMPORTS\n",
        "# -------------------------------\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report\n",
        "import lightgbm as lgb\n",
        "from lightgbm import early_stopping, log_evaluation\n",
        "import matplotlib.pyplot as plt\n",
        "from astropy.timeseries import LombScargle  # For periodicity features\n",
        "import joblib\n",
        "\n",
        "# -------------------------------\n",
        "# PARAMETERS\n",
        "# -------------------------------\n",
        "LABEL_FILE = \"/content/drive/MyDrive/labels_existence.csv\"\n",
        "LIGHTCURVE_DIR = \"/content/drive/MyDrive/Data\"\n",
        "\n",
        "# -------------------------------\n",
        "# FEATURE EXTRACTION FUNCTION\n",
        "# -------------------------------\n",
        "def extract_features(lc_file):\n",
        "    \"\"\"\n",
        "    Reads a lightcurve CSV and returns statistical + periodic + segment features.\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(lc_file)\n",
        "\n",
        "    # Use correct column names\n",
        "    time = df['time_bjd'].values\n",
        "    flux = df['flux'].values\n",
        "    flux_err = df['flux_err'].values\n",
        "\n",
        "    features = {}\n",
        "\n",
        "    # --- Basic statistics ---\n",
        "    features['flux_mean'] = np.mean(flux)\n",
        "    features['flux_std'] = np.std(flux)\n",
        "    features['flux_median'] = np.median(flux)\n",
        "    features['flux_min'] = np.min(flux)\n",
        "    features['flux_max'] = np.max(flux)\n",
        "    features['flux_skew'] = pd.Series(flux).skew()\n",
        "    features['flux_kurt'] = pd.Series(flux).kurt()\n",
        "\n",
        "    # --- Dip features (transit proxy) ---\n",
        "    flux_diff = features['flux_mean'] - flux\n",
        "    features['dip_max'] = np.max(flux_diff)\n",
        "    features['dip_mean'] = np.mean(flux_diff)\n",
        "    features['dip_std'] = np.std(flux_diff)\n",
        "\n",
        "    # --- Periodicity features using Lombâ€“Scargle ---\n",
        "    try:\n",
        "        frequency, power = LombScargle(time, flux).autopower()\n",
        "        best_freq = frequency[np.argmax(power)]\n",
        "        features['best_period'] = 1 / best_freq if best_freq > 0 else 0\n",
        "        features['period_power'] = np.max(power)\n",
        "    except Exception:\n",
        "        features['best_period'] = 0\n",
        "        features['period_power'] = 0\n",
        "\n",
        "    # --- Segment-based slope & variance ---\n",
        "    n_segments = 5\n",
        "    segment_len = len(flux) // n_segments if len(flux) >= n_segments else len(flux)\n",
        "    slopes = []\n",
        "    vars_ = []\n",
        "    for i in range(n_segments):\n",
        "        start = i * segment_len\n",
        "        end = start + segment_len\n",
        "        seg_time = time[start:end]\n",
        "        seg_flux = flux[start:end]\n",
        "        if len(seg_time) > 1:\n",
        "            coeffs = np.polyfit(seg_time, seg_flux, 1)\n",
        "            slopes.append(coeffs[0])\n",
        "            vars_.append(np.var(seg_flux))\n",
        "    features['slope_mean'] = np.mean(slopes) if slopes else 0\n",
        "    features['slope_std'] = np.std(slopes) if slopes else 0\n",
        "    features['var_mean'] = np.mean(vars_) if vars_ else 0\n",
        "    features['var_std'] = np.std(vars_) if vars_ else 0\n",
        "\n",
        "    return features\n",
        "\n",
        "# -------------------------------\n",
        "# LOAD DATA AND EXTRACT FEATURES\n",
        "# -------------------------------\n",
        "labels_df = pd.read_csv(LABEL_FILE)\n",
        "\n",
        "feature_list = []\n",
        "valid_targets = []\n",
        "for idx, row in labels_df.iterrows():\n",
        "    lc_file = row['lightcurve_file']\n",
        "    if os.path.exists(lc_file):\n",
        "        feats = extract_features(lc_file)\n",
        "        feature_list.append(feats)\n",
        "        valid_targets.append(row['target'])\n",
        "    else:\n",
        "        print(f\"File missing: {lc_file}\")\n",
        "\n",
        "X = pd.DataFrame(feature_list)\n",
        "y = np.array(valid_targets)\n",
        "\n",
        "print(\"âœ… Feature matrix shape:\", X.shape)\n",
        "print(\"âœ… Target vector shape:\", y.shape)\n",
        "\n",
        "# -------------------------------\n",
        "# TRAIN-TEST SPLIT\n",
        "# -------------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.1, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# FEATURE SCALING\n",
        "# -------------------------------\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# -------------------------------\n",
        "# LIGHTGBM MODEL\n",
        "# -------------------------------\n",
        "model = lgb.LGBMClassifier(\n",
        "    n_estimators=1000,\n",
        "    learning_rate=0.03,\n",
        "    max_depth=8,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train with callbacks for early stopping & logging\n",
        "model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    eval_set=[(X_test_scaled, y_test)],\n",
        "    eval_metric='binary_logloss',\n",
        "    callbacks=[\n",
        "        early_stopping(stopping_rounds=50),\n",
        "        log_evaluation(period=20)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# EVALUATION\n",
        "# -------------------------------\n",
        "y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "roc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "print(f\"\\nğŸ¯ Test Accuracy: {acc:.4f}\")\n",
        "print(f\"ğŸª ROC AUC Score: {roc:.4f}\")\n",
        "print(\"ğŸ“Š Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.imshow(cm, cmap='Blues')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.colorbar()\n",
        "plt.xticks([0,1], [\"No Planet\",\"Planet\"])\n",
        "plt.yticks([0,1], [\"No Planet\",\"Planet\"])\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        plt.text(j,i,cm[i,j],ha='center',va='center',color='red',fontsize=16)\n",
        "plt.show()\n",
        "\n",
        "# -------------------------------\n",
        "# SAVE MODEL AND SCALER\n",
        "# -------------------------------\n",
        "joblib.dump(model, \"/content/lgb_exoplanet_model.pkl\")\n",
        "joblib.dump(scaler, \"/content/scaler.pkl\")\n",
        "print(\"âœ… Model and scaler saved to /content/\")\n"
      ],
      "metadata": {
        "id": "xP--U9QBO5fD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "803c1f83-afd1-45d3-d047-f5268ffbc0eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1165912324.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mlc_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lightcurve_file'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlc_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlc_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mfeature_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mvalid_targets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1165912324.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(lc_file)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# --- Periodicity features using Lombâ€“Scargle ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mfrequency\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpower\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLombScargle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflux\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautopower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mbest_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrequency\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'best_period'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbest_freq\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbest_freq\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/astropy/timeseries/periodograms/lombscargle/core.py\u001b[0m in \u001b[0;36mautopower\u001b[0;34m(self, method, method_kwds, normalization, samples_per_peak, nyquist_factor, minimum_frequency, maximum_frequency)\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mmaximum_frequency\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximum_frequency\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         )\n\u001b[0;32m--> 320\u001b[0;31m         power = self.power(\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0mfrequency\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mnormalization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormalization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/astropy/timeseries/periodograms/lombscargle/core.py\u001b[0m in \u001b[0;36mpower\u001b[0;34m(self, frequency, normalization, method, assume_regular_frequency, method_kwds)\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0mnormalization\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0mfrequency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_frequency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrequency\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         power = lombscargle(\n\u001b[0m\u001b[1;32m    382\u001b[0m             \u001b[0;34m*\u001b[0m\u001b[0mstrip_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mfrequency\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrip_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrequency\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/astropy/timeseries/periodograms/lombscargle/implementations/main.py\u001b[0m in \u001b[0;36mlombscargle\u001b[0;34m(t, y, dy, frequency, method, assume_regular_frequency, normalization, fit_mean, center_data, method_kwds, nterms)\u001b[0m\n\u001b[1;32m    226\u001b[0m             )\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m     \u001b[0mPLS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMETHODS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mPLS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/astropy/timeseries/periodograms/lombscargle/implementations/fast_impl.py\u001b[0m in \u001b[0;36mlombscargle_fast\u001b[0;34m(t, y, dy, f0, df, Nf, center_data, fit_mean, normalization, use_fft, trig_sum_kwds)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;31m# ----------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# 1. compute functions of the time-shift tau at each frequency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mSh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrig_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0mS2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrig_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/astropy/timeseries/periodograms/lombscargle/implementations/utils.py\u001b[0m in \u001b[0;36mtrig_sum\u001b[0;34m(t, h, df, N, f0, freq_factor, oversampling, use_fft, Mfft)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextirpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNfft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMfft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mfftgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mifft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mt0\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/fft/_pocketfft.py\u001b[0m in \u001b[0;36mifft\u001b[0;34m(a, n, axis, norm, out)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_raw_fft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/fft/_pocketfft.py\u001b[0m in \u001b[0;36m_raw_fft\u001b[0;34m(a, n, axis, is_real, is_forward, norm, out)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output array has wrong shape.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow scikit-learn astropy tqdm pandas numpy scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXmPsgSFH8Vu",
        "outputId": "4316c432-1d61-4f30-d4b0-e9d8d5ef2009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: astropy in /usr/local/lib/python3.12/dist-packages (7.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.75.1)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: pyerfa>=2.0.1.1 in /usr/local/lib/python3.12/dist-packages (from astropy) (2.0.1.5)\n",
            "Requirement already satisfied: astropy-iers-data>=0.2025.4.28.0.37.27 in /usr/local/lib/python3.12/dist-packages (from astropy) (0.2025.9.29.0.35.48)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from astropy) (6.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, math\n",
        "import numpy as np, pandas as pd\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model, Input\n",
        "from scipy.signal import savgol_filter\n",
        "from scipy import stats\n",
        "# Lomb-Scargle (optional, makes useful features)\n",
        "from astropy.timeseries import LombScargle\n"
      ],
      "metadata": {
        "id": "Q6ntHUnMI0r4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LABELS_CSV = \"/content/drive/MyDrive/labels_features.csv\"\n",
        "DATA_DIR = \"/content/drive/MyDrive/Data\"\n",
        "PROCESSED_DIR = \"/content/drive/MyDrive/processed_lc\"   # where we store preprocessed .npz\n",
        "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
        "\n",
        "TARGET_LENGTH = 2048       # resampled length (tune to GPU)\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)\n",
        "\n",
        "TARGET_KEYS = [\n",
        " \"koi_period\",\"koi_depth\",\"koi_prad\",\"koi_teq\",\"koi_steff\",\"koi_srad\",\n",
        " \"koi_model_snr\",\"pl_orbsmax\",\"pl_rade\",\"pl_masse\",\"pl_dens\",\"pl_eqt\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "dQ_NOydDJE5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_lc(path):\n",
        "    # robust loader: try different separators\n",
        "    try:\n",
        "        df = pd.read_csv(path)\n",
        "    except Exception:\n",
        "        df = pd.read_csv(path, sep=None, engine='python')  # auto-detect\n",
        "    # find columns by name heuristics\n",
        "    cols = [c.lower() for c in df.columns]\n",
        "    time_col = [c for c in df.columns if 'time' in c.lower()][0]\n",
        "    flux_col = [c for c in df.columns if c.lower().startswith('flux') and 'err' not in c.lower()][0]\n",
        "    # flux_err optional\n",
        "    flux_err_candidates = [c for c in df.columns if 'err' in c.lower() or 'error' in c.lower()]\n",
        "    flux_err_col = flux_err_candidates[0] if flux_err_candidates else None\n",
        "    time = df[time_col].values.astype(float)\n",
        "    flux = df[flux_col].values.astype(float)\n",
        "    flux_err = df[flux_err_col].values.astype(float) if flux_err_col else None\n",
        "    # sort\n",
        "    order = np.argsort(time)\n",
        "    return time[order], flux[order], (flux_err[order] if flux_err is not None else None)\n",
        "\n",
        "def safe_savgol(y, window_frac=0.02, polyorder=3):\n",
        "    n = len(y)\n",
        "    w = max(5, int(n * window_frac))\n",
        "    if w % 2 == 0: w += 1\n",
        "    if w >= n:\n",
        "        return np.median(y) * np.ones_like(y)\n",
        "    try:\n",
        "        return savgol_filter(y, w, polyorder)\n",
        "    except Exception:\n",
        "        return np.median(y) * np.ones_like(y)\n",
        "\n",
        "def compute_tabular_features(time, flux):\n",
        "    feats = {}\n",
        "    # basic stats\n",
        "    feats['mean'] = np.nanmean(flux)\n",
        "    feats['std'] = np.nanstd(flux)\n",
        "    feats['median'] = np.nanmedian(flux)\n",
        "    feats['min'] = np.nanmin(flux)\n",
        "    feats['max'] = np.nanmax(flux)\n",
        "    feats['skew'] = float(stats.skew(flux, nan_policy='omit'))\n",
        "    feats['kurtosis'] = float(stats.kurtosis(flux, nan_policy='omit'))\n",
        "    for p in [1,5,25,50,75,95,99]:\n",
        "        feats[f'p{p}'] = np.nanpercentile(flux, p)\n",
        "    feats['mad'] = np.nanmedian(np.abs(flux - np.nanmedian(flux)))\n",
        "    feats['rms'] = np.sqrt(np.nanmean(flux**2))\n",
        "    # fraction of outliers (zscore > 5)\n",
        "    z = np.abs(stats.zscore(flux, nan_policy='omit'))\n",
        "    feats['frac_outliers'] = float(np.sum(z>5) / len(flux))\n",
        "\n",
        "    # Lomb-Scargle period estimate (fast approximate)\n",
        "    try:\n",
        "        # restrict to physically plausible periods: 0.1 to 1000 days (adjust if needed)\n",
        "        ls = LombScargle(time, flux)\n",
        "        freq, power = ls.autopower(minimum_frequency=1/1000, maximum_frequency=1/0.1, samples_per_peak=2)\n",
        "        best_idx = np.nanargmax(power)\n",
        "        best_freq = freq[best_idx]\n",
        "        feats['ls_period'] = float(1.0 / best_freq)\n",
        "        feats['ls_power'] = float(power[best_idx])\n",
        "    except Exception:\n",
        "        feats['ls_period'] = np.nan\n",
        "        feats['ls_power'] = np.nan\n",
        "    return feats\n",
        "\n",
        "def preprocess_and_save(path, out_path, target_length=TARGET_LENGTH):\n",
        "    time, flux, ferr = read_lc(path)\n",
        "    # drop NaNs\n",
        "    mask = np.isfinite(time) & np.isfinite(flux)\n",
        "    time, flux = time[mask], flux[mask]\n",
        "    if len(time) < 50:\n",
        "        raise ValueError(f\"too few points in {path}\")\n",
        "    # divide by median baseline\n",
        "    flux = flux / np.nanmedian(flux)\n",
        "    # detrend\n",
        "    trend = safe_savgol(flux, window_frac=0.02, polyorder=3)\n",
        "    flux_detrended = flux / np.maximum(trend, 1e-12) - 1.0   # relative flux\n",
        "    # optional clip extreme outliers\n",
        "    med = np.nanmedian(flux_detrended)\n",
        "    mad = np.nanmedian(np.abs(flux_detrended - med))\n",
        "    clip_low, clip_high = med - 10*mad, med + 10*mad\n",
        "    flux_detrended = np.clip(flux_detrended, clip_low, clip_high)\n",
        "\n",
        "    # uniform resample\n",
        "    uni_time = np.linspace(time.min(), time.max(), target_length)\n",
        "    uni_flux = np.interp(uni_time, time, flux_detrended)\n",
        "\n",
        "    # standardize to zero mean, unit std (per light curve)\n",
        "    uni_flux = (uni_flux - np.mean(uni_flux)) / (np.std(uni_flux) + 1e-12)\n",
        "\n",
        "    # tabular features computed on detrended original (not resampled) for more fidelity\n",
        "    tab_feats = compute_tabular_features(time, flux_detrended)\n",
        "\n",
        "    # save\n",
        "    np.savez_compressed(out_path, flux=uni_flux.astype(np.float32), **tab_feats)\n",
        "    return out_path\n"
      ],
      "metadata": {
        "id": "jAxLvIHUWtKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_df = pd.read_csv(LABELS_CSV)\n",
        "# ensure path column name exactly matches; user said it's 'lightcurve_file'\n",
        "for idx, row in tqdm(labels_df.iterrows(), total=len(labels_df)):\n",
        "    lc_path = row['lightcurve_file']\n",
        "    if not os.path.exists(lc_path):\n",
        "        print(\"missing:\", lc_path)\n",
        "        continue\n",
        "    fname = os.path.basename(lc_path).replace('.csv','.npz')\n",
        "    out_path = os.path.join(PROCESSED_DIR, fname)\n",
        "    if not os.path.exists(out_path):\n",
        "        try:\n",
        "            preprocess_and_save(lc_path, out_path, target_length=TARGET_LENGTH)\n",
        "        except Exception as e:\n",
        "            print(\"failed\", lc_path, e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hFLD15NXjSl",
        "outputId": "2a548a6a-5d52-4747-c046-59712b8f6b67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4985/4985 [1:59:39<00:00,  1.44s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "processed_files = sorted(glob(os.path.join(PROCESSED_DIR, \"*.npz\")))\n",
        "\n",
        "X_ts = []\n",
        "X_tab = []\n",
        "Y = []\n",
        "rows = []\n",
        "\n",
        "tab_keys = ['mean','std','median','min','max','skew','kurtosis','mad','rms','frac_outliers','ls_period','ls_power']\n",
        "\n",
        "for p in tqdm(processed_files):\n",
        "    base_csv = os.path.basename(p).replace('.npz','.csv')\n",
        "\n",
        "    # find matching label row\n",
        "    match = labels_df[labels_df['lightcurve_file'].str.endswith(base_csv)]\n",
        "    if match.empty:\n",
        "        match = labels_df[labels_df['lightcurve_file'].str.contains(base_csv.replace('_lightcurve.csv',''))]\n",
        "        if match.empty:\n",
        "            continue\n",
        "\n",
        "    row = match.iloc[0]\n",
        "\n",
        "    arr = np.load(p)\n",
        "    flux = arr['flux']  # shape (TARGET_LENGTH,)\n",
        "\n",
        "    tab = [float(arr[k]) if k in arr else np.nan for k in tab_keys]\n",
        "\n",
        "    X_ts.append(flux.reshape(-1,1))\n",
        "    X_tab.append(tab)\n",
        "    Y.append([row[k] for k in TARGET_KEYS])\n",
        "    rows.append(row.name)\n",
        "\n",
        "X_ts = np.array(X_ts, dtype=np.float32)\n",
        "X_tab = np.array(X_tab, dtype=np.float32)\n",
        "Y = np.array(Y, dtype=np.float32)\n",
        "\n",
        "print(X_ts.shape, X_tab.shape, Y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvcP370-zYAu",
        "outputId": "c7163223-06f4-47ee-debc-ab518effdca0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4315/4315 [03:12<00:00, 22.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4315, 2048, 1) (4315, 12) (4315, 12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "apply_log = {}\n",
        "Y_proc = Y.copy()\n",
        "\n",
        "for i, key in enumerate(TARGET_KEYS):\n",
        "    arr = Y[:, i]\n",
        "\n",
        "    if np.all(arr > 0):\n",
        "        # Work on a copy to avoid overflow in skew\n",
        "        arr_copy = np.copy(arr)\n",
        "\n",
        "        # Clip extreme outliers just for skewness detection\n",
        "        arr_copy = np.clip(arr_copy, np.percentile(arr_copy, 1), np.percentile(arr_copy, 99))\n",
        "\n",
        "        try:\n",
        "            skewness = stats.skew(arr_copy, nan_policy='omit')\n",
        "        except Exception as e:\n",
        "            print(f\"Warning computing skew for {key}: {e}\")\n",
        "            skewness = 0\n",
        "\n",
        "        apply_log[key] = (skewness > 1.0)\n",
        "    else:\n",
        "        apply_log[key] = False\n",
        "\n",
        "# âœ… Apply log1p where needed\n",
        "for i, key in enumerate(TARGET_KEYS):\n",
        "    if apply_log[key]:\n",
        "        Y_proc[:, i] = np.log1p(Y_proc[:, i])\n",
        "\n",
        "# âœ… Scale targets\n",
        "target_scaler = StandardScaler()\n",
        "Y_scaled = target_scaler.fit_transform(Y_proc)\n",
        "\n",
        "print(\"Transform applied to targets:\", apply_log)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hMK7AIc1IFW",
        "outputId": "97fa6b7a-079b-4f40-d739-1eb5f36d9ac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transform applied to targets: {'koi_period': np.True_, 'koi_depth': np.True_, 'koi_prad': np.True_, 'koi_teq': np.True_, 'koi_steff': np.False_, 'koi_srad': np.True_, 'koi_model_snr': np.True_, 'pl_orbsmax': np.True_, 'pl_rade': np.True_, 'pl_masse': np.True_, 'pl_dens': np.True_, 'pl_eqt': np.True_}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.arange(len(Y_scaled))\n",
        "train_idx, test_idx = train_test_split(idx, test_size=0.30, random_state=RANDOM_SEED)\n",
        "val_idx, test_idx = train_test_split(test_idx, test_size=0.5, random_state=RANDOM_SEED)\n",
        "\n",
        "X_ts_train, X_ts_val, X_ts_test = X_ts[train_idx], X_ts[val_idx], X_ts[test_idx]\n",
        "X_tab_train, X_tab_val, X_tab_test = X_tab[train_idx], X_tab[val_idx], X_tab[test_idx]\n",
        "y_train, y_val, y_test = Y_scaled[train_idx], Y_scaled[val_idx], Y_scaled[test_idx]\n",
        "\n",
        "print(\"train/val/test:\", len(train_idx), len(val_idx), len(test_idx))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0-Fcuen4a13",
        "outputId": "95915baf-3984-433d-de9a-87375af9ec4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train/val/test: 3020 647 648\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_hybrid_model(input_length=TARGET_LENGTH, n_tab=X_tab.shape[1], n_out=len(TARGET_KEYS)):\n",
        "    # time-series branch\n",
        "    ts_in = Input(shape=(input_length,1), name='lc_input')\n",
        "    x = layers.Conv1D(32, 11, padding='same', activation=None)(ts_in)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.MaxPooling1D(4)(x)\n",
        "\n",
        "    x = layers.Conv1D(64, 7, padding='same', activation=None)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.MaxPooling1D(4)(x)\n",
        "\n",
        "    x = layers.Conv1D(128, 5, padding='same', activation=None)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    # tabular branch\n",
        "    tab_in = Input(shape=(n_tab,), name='tab_input')\n",
        "    t = layers.Dense(64, activation='relu')(tab_in)\n",
        "    t = layers.BatchNormalization()(t)\n",
        "    t = layers.Dropout(0.2)(t)\n",
        "\n",
        "    # concatenate\n",
        "    concat = layers.Concatenate()([x, t])\n",
        "    h = layers.Dense(128, activation='relu')(concat)\n",
        "    h = layers.Dropout(0.25)(h)\n",
        "    h = layers.Dense(64, activation='relu')(h)\n",
        "\n",
        "    out = layers.Dense(n_out, activation='linear', name='out')(h)\n",
        "\n",
        "    model = Model(inputs=[ts_in, tab_in], outputs=out)\n",
        "    # Huber loss is robust to outliers; use Adam optimizer\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "                  loss=tf.keras.losses.Huber(), metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "model = build_hybrid_model()\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "R-Gjdegd4s3o",
        "outputId": "e23d3129-2878-47b9-deff-30af20deff24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ lc_input            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m, \u001b[38;5;34m1\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d (\u001b[38;5;33mConv1D\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m, \u001b[38;5;34m32\u001b[0m)  â”‚        \u001b[38;5;34m384\u001b[0m â”‚ lc_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m, \u001b[38;5;34m32\u001b[0m)  â”‚        \u001b[38;5;34m128\u001b[0m â”‚ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m, \u001b[38;5;34m32\u001b[0m)  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling1d       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m32\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
              "â”‚ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚     \u001b[38;5;34m14,400\u001b[0m â”‚ max_pooling1d[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚        \u001b[38;5;34m256\u001b[0m â”‚ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_1        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling1d_1     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  â”‚     \u001b[38;5;34m41,088\u001b[0m â”‚ max_pooling1d_1[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  â”‚        \u001b[38;5;34m512\u001b[0m â”‚ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_2        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ tab_input           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePoolâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m832\u001b[0m â”‚ tab_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚     \u001b[38;5;34m16,512\u001b[0m â”‚ global_average_pâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m256\u001b[0m â”‚ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ concatenate         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    â”‚\n",
              "â”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚                   â”‚            â”‚ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚     \u001b[38;5;34m24,704\u001b[0m â”‚ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚      \u001b[38;5;34m8,256\u001b[0m â”‚ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ out (\u001b[38;5;33mDense\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)        â”‚        \u001b[38;5;34m780\u001b[0m â”‚ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ lc_input            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> â”‚ lc_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling1d       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">14,400</span> â”‚ max_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_1        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling1d_1     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> â”‚ max_pooling1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ activation_2        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ tab_input           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePoolâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> â”‚ tab_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> â”‚ global_average_pâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ concatenate         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚                   â”‚            â”‚ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> â”‚ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">780</span> â”‚ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m108,108\u001b[0m (422.30 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">108,108</span> (422.30 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m107,532\u001b[0m (420.05 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">107,532</span> (420.05 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m576\u001b[0m (2.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> (2.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epochs = 100\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=12, restore_best_weights=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=6),\n",
        "    tf.keras.callbacks.ModelCheckpoint('/content/drive/MyDrive/best_model.h5', save_best_only=True, monitor='val_loss')\n",
        "]\n",
        "\n",
        "# simple data augmentation function\n",
        "def augment_batch(Xb_ts, sigma=0.02):\n",
        "    noise = np.random.normal(0, sigma, size=Xb_ts.shape)\n",
        "    return Xb_ts + noise\n",
        "\n",
        "# training loop with in-memory arrays\n",
        "history = model.fit(\n",
        "    x = [augment_batch(X_ts_train, sigma=0.01), X_tab_train],\n",
        "    y = y_train,\n",
        "    validation_data = ([X_ts_val, X_tab_val], y_val),\n",
        "    epochs = epochs,\n",
        "    batch_size = batch_size,\n",
        "    callbacks = callbacks,\n",
        "    shuffle=True\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIVunG9L5JGN",
        "outputId": "aa2e070b-2ce9-469e-90ab-ea2c4b8e41c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - loss: 0.3666 - mae: 0.7182"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 173ms/step - loss: 0.3662 - mae: 0.7177 - val_loss: 0.3461 - val_mae: 0.7076 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 0.2779 - mae: 0.5956"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 182ms/step - loss: 0.2779 - mae: 0.5956 - val_loss: 0.3186 - val_mae: 0.6662 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - loss: 0.2691 - mae: 0.5843"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 183ms/step - loss: 0.2691 - mae: 0.5843 - val_loss: 0.3044 - val_mae: 0.6382 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.2617 - mae: 0.5726"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 175ms/step - loss: 0.2617 - mae: 0.5727 - val_loss: 0.2959 - val_mae: 0.6327 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 165ms/step - loss: 0.2586 - mae: 0.5674 - val_loss: 0.3202 - val_mae: 0.6690 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 170ms/step - loss: 0.2539 - mae: 0.5599 - val_loss: 0.2989 - val_mae: 0.6374 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.2488 - mae: 0.5535"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 173ms/step - loss: 0.2488 - mae: 0.5535 - val_loss: 0.2957 - val_mae: 0.6327 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - loss: 0.2487 - mae: 0.5523"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 182ms/step - loss: 0.2487 - mae: 0.5523 - val_loss: 0.2756 - val_mae: 0.5974 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.2451 - mae: 0.5470"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 183ms/step - loss: 0.2452 - mae: 0.5471 - val_loss: 0.2728 - val_mae: 0.5912 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.2413 - mae: 0.5397"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 173ms/step - loss: 0.2414 - mae: 0.5397 - val_loss: 0.2715 - val_mae: 0.5859 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - loss: 0.2392 - mae: 0.5384"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 174ms/step - loss: 0.2393 - mae: 0.5384 - val_loss: 0.2640 - val_mae: 0.5694 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - loss: 0.2385 - mae: 0.5380"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 173ms/step - loss: 0.2385 - mae: 0.5380 - val_loss: 0.2559 - val_mae: 0.5586 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 166ms/step - loss: 0.2329 - mae: 0.5276 - val_loss: 0.2620 - val_mae: 0.5596 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 165ms/step - loss: 0.2331 - mae: 0.5301 - val_loss: 0.2625 - val_mae: 0.5720 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 163ms/step - loss: 0.2320 - mae: 0.5257 - val_loss: 0.2939 - val_mae: 0.6216 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 164ms/step - loss: 0.2315 - mae: 0.5254 - val_loss: 0.2723 - val_mae: 0.5848 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 163ms/step - loss: 0.2275 - mae: 0.5192 - val_loss: 0.2680 - val_mae: 0.5750 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 164ms/step - loss: 0.2257 - mae: 0.5157 - val_loss: 0.3122 - val_mae: 0.6565 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 171ms/step - loss: 0.2231 - mae: 0.5139 - val_loss: 0.3226 - val_mae: 0.6666 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 186ms/step - loss: 0.2179 - mae: 0.5049 - val_loss: 0.2969 - val_mae: 0.6243 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 163ms/step - loss: 0.2162 - mae: 0.5039 - val_loss: 0.2739 - val_mae: 0.5888 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 170ms/step - loss: 0.2138 - mae: 0.5010 - val_loss: 0.3012 - val_mae: 0.6340 - learning_rate: 5.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 164ms/step - loss: 0.2090 - mae: 0.4929 - val_loss: 0.2605 - val_mae: 0.5675 - learning_rate: 5.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m95/95\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 163ms/step - loss: 0.2086 - mae: 0.4926 - val_loss: 0.4440 - val_mae: 0.8160 - learning_rate: 5.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# ----------------------------\n",
        "# Load model & make predictions\n",
        "# ----------------------------\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/best_model.h5', compile=False)\n",
        "\n",
        "# Predict scaled targets\n",
        "y_pred_scaled = model.predict([X_ts_test, X_tab_test], batch_size=32)\n",
        "\n",
        "# Inverse scale\n",
        "y_pred_proc = target_scaler.inverse_transform(y_pred_scaled)\n",
        "y_true_proc = target_scaler.inverse_transform(y_test)\n",
        "\n",
        "# ----------------------------\n",
        "# Invert log transforms properly\n",
        "# ----------------------------\n",
        "y_pred_final = y_pred_proc.copy()\n",
        "y_true_final = y_true_proc.copy()\n",
        "\n",
        "for i, key in enumerate(TARGET_KEYS):\n",
        "    if apply_log.get(key, False):\n",
        "        # Clip values before expm1 to avoid overflow (exp(>700) blows up)\n",
        "        y_pred_final[:, i] = np.expm1(np.clip(y_pred_final[:, i], a_min=None, a_max=700))\n",
        "        y_true_final[:, i] = np.expm1(np.clip(y_true_final[:, i], a_min=None, a_max=700))\n",
        "\n",
        "# ----------------------------\n",
        "# Compute metrics per feature\n",
        "# ----------------------------\n",
        "results = []\n",
        "for i, key in enumerate(TARGET_KEYS):\n",
        "    y_pred_i = y_pred_final[:, i]\n",
        "    y_true_i = y_true_final[:, i]\n",
        "    mae = mean_absolute_error(y_true_i, y_pred_i)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true_i, y_pred_i))\n",
        "    r2 = r2_score(y_true_i, y_pred_i)\n",
        "    results.append({\n",
        "        \"Feature\": key,\n",
        "        \"MAE\": mae,\n",
        "        \"RMSE\": rmse,\n",
        "        \"RÂ²\": r2\n",
        "    })\n",
        "\n",
        "# ----------------------------\n",
        "# Display results in a table\n",
        "# ----------------------------\n",
        "df_results = pd.DataFrame(results)\n",
        "df_results = df_results.sort_values(by=\"RÂ²\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"\\nğŸ“Š Model Evaluation Results:\")\n",
        "print(df_results.to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_2y8Qv8RbG9",
        "outputId": "081c20d8-d65b-4437-a61d-ba8b8eb7bb63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m21/21\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step\n",
            "\n",
            "ğŸ“Š Model Evaluation Results:\n",
            "      Feature          MAE         RMSE        RÂ²\n",
            "koi_model_snr 1.835538e+02 6.349469e+02  0.305351\n",
            "    koi_depth 2.229066e+04 8.107854e+04  0.256726\n",
            "    koi_steff 4.795311e+02 6.930482e+02  0.194255\n",
            "      pl_dens 2.163015e+01 6.495804e+01  0.161820\n",
            "       pl_eqt 4.968494e+02 7.552704e+02  0.109971\n",
            "      koi_teq 4.985828e+02 7.588688e+02  0.101470\n",
            "   pl_orbsmax 1.846218e-01 3.106520e-01  0.042208\n",
            "      pl_rade 1.885620e+01 8.861204e+01  0.038803\n",
            "     koi_prad 1.871526e+01 8.871819e+01  0.036498\n",
            "     koi_srad 1.087653e+00 9.882924e+00 -0.004058\n",
            "     pl_masse 1.118139e+09 1.591684e+10 -0.004956\n",
            "   koi_period 5.606660e+01 1.316898e+02 -0.111359\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow scikit-learn astropy tqdm pandas numpy scipy\n",
        "\n",
        "import os, json, math\n",
        "import numpy as np, pandas as pd\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model, Input\n",
        "from scipy.signal import savgol_filter\n",
        "from scipy import stats\n",
        "from astropy.timeseries import LombScargle\n",
        "\n",
        "# =========================\n",
        "# PATHS & CONFIG\n",
        "# =========================\n",
        "LABELS_CSV = \"/content/drive/MyDrive/labels_features.csv\"\n",
        "DATA_DIR = \"/content/drive/MyDrive/Data\"\n",
        "PROCESSED_DIR = \"/content/drive/MyDrive/processed_lc\"\n",
        "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
        "\n",
        "TARGET_LENGTH = 2048\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)\n",
        "\n",
        "TARGET_KEYS = [\n",
        " \"koi_period\",\"koi_depth\",\"koi_prad\",\"koi_teq\",\"koi_steff\",\"koi_srad\",\n",
        " \"koi_model_snr\",\"pl_orbsmax\",\"pl_rade\",\"pl_masse\",\"pl_dens\",\"pl_eqt\"\n",
        "]\n",
        "\n",
        "# =========================\n",
        "# DATA LOADING HELPERS\n",
        "# =========================\n",
        "def read_lc(path):\n",
        "    try:\n",
        "        df = pd.read_csv(path)\n",
        "    except Exception:\n",
        "        df = pd.read_csv(path, sep=None, engine='python')\n",
        "    time_col = [c for c in df.columns if 'time' in c.lower()][0]\n",
        "    flux_col = [c for c in df.columns if c.lower().startswith('flux') and 'err' not in c.lower()][0]\n",
        "    time = df[time_col].values.astype(float)\n",
        "    flux = df[flux_col].values.astype(float)\n",
        "    order = np.argsort(time)\n",
        "    return time[order], flux[order]\n",
        "\n",
        "def safe_savgol(y, window_frac=0.02, polyorder=3):\n",
        "    n = len(y)\n",
        "    w = max(5, int(n * window_frac))\n",
        "    if w % 2 == 0: w += 1\n",
        "    if w >= n: return np.median(y) * np.ones_like(y)\n",
        "    try: return savgol_filter(y, w, polyorder)\n",
        "    except: return np.median(y) * np.ones_like(y)\n",
        "\n",
        "def compute_tabular_features(time, flux):\n",
        "    feats = {}\n",
        "    feats['mean'] = np.nanmean(flux)\n",
        "    feats['std'] = np.nanstd(flux)\n",
        "    feats['median'] = np.nanmedian(flux)\n",
        "    feats['min'] = np.nanmin(flux)\n",
        "    feats['max'] = np.nanmax(flux)\n",
        "    feats['skew'] = float(stats.skew(flux, nan_policy='omit'))\n",
        "    feats['kurtosis'] = float(stats.kurtosis(flux, nan_policy='omit'))\n",
        "    for p in [1,5,25,50,75,95,99]:\n",
        "        feats[f'p{p}'] = np.nanpercentile(flux, p)\n",
        "    feats['mad'] = np.nanmedian(np.abs(flux - np.nanmedian(flux)))\n",
        "    feats['rms'] = np.sqrt(np.nanmean(flux**2))\n",
        "    z = np.abs(stats.zscore(flux, nan_policy='omit'))\n",
        "    feats['frac_outliers'] = float(np.sum(z>5) / len(flux))\n",
        "    try:\n",
        "        ls = LombScargle(time, flux)\n",
        "        freq, power = ls.autopower(minimum_frequency=1/1000, maximum_frequency=1/0.1)\n",
        "        best_idx = np.nanargmax(power)\n",
        "        feats['ls_period'] = float(1.0 / freq[best_idx])\n",
        "        feats['ls_power'] = float(power[best_idx])\n",
        "    except:\n",
        "        feats['ls_period'] = np.nan\n",
        "        feats['ls_power'] = np.nan\n",
        "    return feats\n",
        "\n",
        "def preprocess_and_save(path, out_path, target_length=TARGET_LENGTH):\n",
        "    time, flux = read_lc(path)\n",
        "    mask = np.isfinite(time) & np.isfinite(flux)\n",
        "    time, flux = time[mask], flux[mask]\n",
        "    if len(time) < 50:\n",
        "        raise ValueError(\"too few points\")\n",
        "\n",
        "    flux = flux / np.nanmedian(flux)\n",
        "    trend = safe_savgol(flux)\n",
        "    flux_detrended = flux / np.maximum(trend, 1e-12) - 1.0\n",
        "\n",
        "    med = np.nanmedian(flux_detrended)\n",
        "    mad = np.nanmedian(np.abs(flux_detrended - med))\n",
        "    flux_detrended = np.clip(flux_detrended, med-10*mad, med+10*mad)\n",
        "\n",
        "    uni_time = np.linspace(time.min(), time.max(), target_length)\n",
        "    uni_flux = np.interp(uni_time, time, flux_detrended)\n",
        "    uni_flux = (uni_flux - np.mean(uni_flux)) / (np.std(uni_flux)+1e-12)\n",
        "\n",
        "    tab_feats = compute_tabular_features(time, flux_detrended)\n",
        "    np.savez_compressed(out_path, flux=uni_flux.astype(np.float32), **tab_feats)\n",
        "    return out_path\n",
        "\n",
        "# =========================\n",
        "# BUILD DATA ARRAYS\n",
        "# =========================\n",
        "labels_df = pd.read_csv(LABELS_CSV)\n",
        "for idx, row in tqdm(labels_df.iterrows(), total=len(labels_df)):\n",
        "    lc_path = row['lightcurve_file']\n",
        "    if not os.path.exists(lc_path): continue\n",
        "    out_path = os.path.join(PROCESSED_DIR, os.path.basename(lc_path).replace('.csv','.npz'))\n",
        "    if not os.path.exists(out_path):\n",
        "        try: preprocess_and_save(lc_path, out_path)\n",
        "        except Exception as e: print(\"fail\", lc_path, e)\n",
        "\n",
        "processed_files = sorted(glob(os.path.join(PROCESSED_DIR, \"*.npz\")))\n",
        "tab_keys = ['mean','std','median','min','max','skew','kurtosis','mad','rms','frac_outliers','ls_period','ls_power']\n",
        "\n",
        "X_ts, X_tab, Y = [], [], []\n",
        "for p in tqdm(processed_files):\n",
        "    base = os.path.basename(p).replace('.npz','.csv')\n",
        "    match = labels_df[labels_df['lightcurve_file'].str.endswith(base)]\n",
        "    if match.empty: continue\n",
        "    row = match.iloc[0]\n",
        "    arr = np.load(p)\n",
        "    X_ts.append(arr['flux'].reshape(-1,1))\n",
        "    X_tab.append([arr.get(k, np.nan) for k in tab_keys])\n",
        "    Y.append([row[k] for k in TARGET_KEYS])\n",
        "\n",
        "X_ts = np.array(X_ts, dtype=np.float32)\n",
        "X_tab = np.array(X_tab, dtype=np.float32)\n",
        "Y = np.array(Y, dtype=np.float32)\n",
        "\n",
        "# =========================\n",
        "# TARGET TRANSFORMS\n",
        "# =========================\n",
        "apply_log = {}\n",
        "Y_proc = Y.copy()\n",
        "for i, key in enumerate(TARGET_KEYS):\n",
        "    arr = Y[:, i]\n",
        "    if np.all(arr > 0):\n",
        "        arr_clip = np.clip(arr, np.percentile(arr,1), np.percentile(arr,99))\n",
        "        skewness = stats.skew(arr_clip, nan_policy='omit')\n",
        "        apply_log[key] = (skewness > 1.0)\n",
        "    else:\n",
        "        apply_log[key] = False\n",
        "\n",
        "for i, key in enumerate(TARGET_KEYS):\n",
        "    if apply_log[key]:\n",
        "        Y_proc[:, i] = np.log1p(Y_proc[:, i])\n",
        "\n",
        "target_scaler = StandardScaler()\n",
        "Y_scaled = target_scaler.fit_transform(Y_proc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yt20Y2yTWD1D",
        "outputId": "b655b385-aed4-46ea-83b3-ed28555e9c3e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: astropy in /usr/local/lib/python3.12/dist-packages (7.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.75.1)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: pyerfa>=2.0.1.1 in /usr/local/lib/python3.12/dist-packages (from astropy) (2.0.1.5)\n",
            "Requirement already satisfied: astropy-iers-data>=0.2025.4.28.0.37.27 in /usr/local/lib/python3.12/dist-packages (from astropy) (0.2025.9.29.0.35.48)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from astropy) (6.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4985/4985 [00:05<00:00, 982.70it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4315/4315 [02:17<00:00, 31.35it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "train_idx, test_idx = train_test_split(np.arange(len(Y_scaled)), test_size=0.3, random_state=RANDOM_SEED)\n",
        "val_idx, test_idx = train_test_split(test_idx, test_size=0.5, random_state=RANDOM_SEED)\n",
        "\n",
        "X_ts_train, X_ts_val, X_ts_test = X_ts[train_idx], X_ts[val_idx], X_ts[test_idx]\n",
        "X_tab_train, X_tab_val, X_tab_test = X_tab[train_idx], X_tab[val_idx], X_tab[test_idx]\n",
        "y_train, y_val, y_test = Y_scaled[train_idx], Y_scaled[val_idx], Y_scaled[test_idx]\n",
        "\n",
        "# =========================\n",
        "# MODEL (CNN + BiLSTM + Tabular)\n",
        "# =========================\n",
        "def build_hybrid_model(input_length, n_tab, n_out):\n",
        "    ts_in = Input(shape=(input_length,1))\n",
        "    x = layers.Conv1D(64, 11, padding='same')(ts_in)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.MaxPooling1D(4)(x)\n",
        "\n",
        "    x = layers.Conv1D(128, 7, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.MaxPooling1D(4)(x)\n",
        "\n",
        "    x = layers.Bidirectional(layers.LSTM(64, return_sequences=False))(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    tab_in = Input(shape=(n_tab,))\n",
        "    t = layers.Dense(64, activation='relu')(tab_in)\n",
        "    t = layers.BatchNormalization()(t)\n",
        "    t = layers.Dropout(0.2)(t)\n",
        "\n",
        "    concat = layers.Concatenate()([x, t])\n",
        "    h = layers.Dense(128, activation='relu')(concat)\n",
        "    h = layers.Dropout(0.3)(h)\n",
        "    out = layers.Dense(n_out, activation='linear')(h)\n",
        "\n",
        "    model = Model([ts_in, tab_in], out)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "                  loss=tf.keras.losses.Huber(), metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "model = build_hybrid_model(TARGET_LENGTH, X_tab.shape[1], len(TARGET_KEYS))\n",
        "model.summary()\n",
        "\n",
        "# =========================\n",
        "# TRAINING\n",
        "# =========================\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=6),\n",
        "    tf.keras.callbacks.ModelCheckpoint('/content/drive/MyDrive/best_model.h5', save_best_only=True, monitor='val_loss')\n",
        "]\n",
        "\n",
        "def augment_ts(x, sigma=0.01):\n",
        "    return x + np.random.normal(0, sigma, size=x.shape)\n",
        "\n",
        "history = model.fit(\n",
        "    [augment_ts(X_ts_train), X_tab_train], y_train,\n",
        "    validation_data=([X_ts_val, X_tab_val], y_val),\n",
        "    epochs=150, batch_size=32, shuffle=True, callbacks=callbacks\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# EVALUATION\n",
        "# =========================\n",
        "best_model = tf.keras.models.load_model('/content/drive/MyDrive/best_model.h5', compile=False)\n",
        "y_pred_scaled = best_model.predict([X_ts_test, X_tab_test], batch_size=32)\n",
        "y_pred_proc = target_scaler.inverse_transform(y_pred_scaled)\n",
        "y_test_proc = target_scaler.inverse_transform(y_test)\n",
        "\n",
        "y_pred_final, y_true_final = y_pred_proc.copy(), y_test_proc.copy()\n",
        "for i, key in enumerate(TARGET_KEYS):\n",
        "    if apply_log[key]:\n",
        "        y_pred_final[:,i] = np.expm1(y_pred_final[:,i])\n",
        "        y_true_final[:,i] = np.expm1(y_true_final[:,i])\n",
        "\n",
        "print(\"\\nğŸ“Š Model Evaluation Results:\")\n",
        "print(f\"{'Feature':15s} {'MAE':>12s} {'RMSE':>12s} {'RÂ²':>8s}\")\n",
        "for i, key in enumerate(TARGET_KEYS):\n",
        "    mae = mean_absolute_error(y_true_final[:,i], y_pred_final[:,i])\n",
        "    rmse = math.sqrt(mean_squared_error(y_true_final[:,i], y_pred_final[:,i]))\n",
        "    r2 = r2_score(y_true_final[:,i], y_pred_final[:,i])\n",
        "    print(f\"{key:15s} {mae:12.4g} {rmse:12.4g} {r2:8.4f}\")"
      ],
      "metadata": {
        "id": "0r9aBiWwXis2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure these are defined first (same as in your training script)\n",
        "TARGET_KEYS = [\n",
        " \"koi_period\",\"koi_depth\",\"koi_prad\",\"koi_teq\",\"koi_steff\",\"koi_srad\",\n",
        " \"koi_model_snr\",\"pl_orbsmax\",\"pl_rade\",\"pl_masse\",\"pl_dens\",\"pl_eqt\"\n",
        "]\n",
        "TARGET_LENGTH = 2048   # or whatever you used during training\n",
        "\n",
        "def infer_single_csv(csv_path, model, target_scaler, apply_log_map,\n",
        "                     target_keys=TARGET_KEYS, target_length=TARGET_LENGTH):\n",
        "    # Read and preprocess the light curve\n",
        "    time, flux = read_lc(csv_path)  # <-- only 2 values now\n",
        "    flux = flux / np.nanmedian(flux)\n",
        "    trend = safe_savgol(flux, window_frac=0.02, polyorder=3)\n",
        "    flux_d = flux / np.maximum(trend,1e-12) - 1.0\n",
        "\n",
        "    # Resample to fixed length\n",
        "    uni_time = np.linspace(time.min(), time.max(), target_length)\n",
        "    uni_flux = np.interp(uni_time, time, flux_d)\n",
        "    uni_flux = (uni_flux - np.mean(uni_flux)) / (np.std(uni_flux) + 1e-12)\n",
        "\n",
        "    # Compute tabular features\n",
        "    tab = compute_tabular_features(time, flux_d)\n",
        "    tab_keys = ['mean','std','median','min','max','skew','kurtosis','mad',\n",
        "                'rms','frac_outliers','ls_period','ls_power']\n",
        "    tab_arr = np.array([tab.get(k, np.nan) for k in tab_keys], dtype=np.float32).reshape(1,-1)\n",
        "\n",
        "    # Make prediction\n",
        "    pred_scaled = model.predict([uni_flux.reshape(1,-1,1), tab_arr])\n",
        "    pred_proc = target_scaler.inverse_transform(pred_scaled)\n",
        "\n",
        "    # Invert log transform where applied\n",
        "    out = {}\n",
        "    for i, key in enumerate(target_keys):\n",
        "        val = pred_proc[0, i]\n",
        "        if apply_log_map.get(key, False):\n",
        "            val = np.expm1(val)\n",
        "        out[key] = float(val)\n",
        "\n",
        "    return json.dumps(out, indent=2)\n",
        "\n"
      ],
      "metadata": {
        "id": "7qaiZUarVtzz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/best_model.h5', compile=False)\n",
        "result_json = infer_single_csv(\n",
        "    \"/content/drive/MyDrive/Data/kepler_1025986_lightcurve.csv\",\n",
        "    model,\n",
        "    target_scaler,\n",
        "    apply_log\n",
        ")\n",
        "print(result_json)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kQbF4YKWjKU",
        "outputId": "36fb32f2-daa0-4f3a-fa4f-6f3e891e6893"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "{\n",
            "  \"koi_period\": 11.039068222045898,\n",
            "  \"koi_depth\": 416.8121032714844,\n",
            "  \"koi_prad\": 2.961278200149536,\n",
            "  \"koi_teq\": 779.3360595703125,\n",
            "  \"koi_steff\": 5516.38671875,\n",
            "  \"koi_srad\": 0.9790551066398621,\n",
            "  \"koi_model_snr\": 25.72298812866211,\n",
            "  \"pl_orbsmax\": 0.1513693928718567,\n",
            "  \"pl_rade\": 2.945708751678467,\n",
            "  \"pl_masse\": 44.26495361328125,\n",
            "  \"pl_dens\": 10.811491012573242,\n",
            "  \"pl_eqt\": 794.79248046875\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}